#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
EnhancedUltraæ¨¡å‹ç»¼åˆæµ‹è¯•è„šæœ¬
æµ‹è¯•æ‰€æœ‰æ”¹è¿›åŠŸèƒ½å¹¶è¯„ä¼°æå‡æ½œåŠ›
"""

import sys
import os
import torch
import torch.nn as nn
from torch_geometric.data import Data
import traceback
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def create_realistic_test_data():
    """åˆ›å»ºçœŸå®çš„æµ‹è¯•æ•°æ®"""
    num_nodes = 1000
    num_relations = 100
    num_edges = 5000
    
    edge_index = torch.randint(0, num_nodes, (2, num_edges))
    edge_type = torch.randint(0, num_relations, (num_edges,))
    
    data = Data()
    data.num_nodes = num_nodes
    data.num_relations = num_relations
    data.edge_index = edge_index
    data.edge_type = edge_type
    
    # Create relation_graph (RelNBFNet needs)
    num_rel_nodes = num_relations
    num_rel_edges = min(500, num_rel_nodes * 10)
    rel_edge_index = torch.randint(0, num_rel_nodes, (2, num_rel_edges))
    rel_edge_type = torch.randint(0, 4, (num_rel_edges,))
    
    relation_graph = Data()
    relation_graph.num_nodes = num_rel_nodes
    relation_graph.num_relations = 4
    relation_graph.edge_index = rel_edge_index
    relation_graph.edge_type = rel_edge_type
    
    data.relation_graph = relation_graph
    
    # If using semma or EnhancedUltra, also need relation_graph2
    from ultra import parse
    try:
        flags = parse.load_flags(os.path.join(os.path.dirname(__file__), "flags.yaml"))
        if flags.run == "semma" or flags.run == "EnhancedUltra":
            relation_graph2 = Data()
            relation_graph2.num_nodes = num_rel_nodes
            relation_graph2.num_relations = 1
            relation_graph2.edge_index = rel_edge_index
            relation_graph2.edge_type = torch.zeros(num_rel_edges, dtype=torch.long)
            relation_graph2.relation_embeddings = None
            data.relation_graph2 = relation_graph2
    except:
        pass
    
    return data

def test_model_initialization():
    """æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–"""
    print("=" * 80)
    print("æµ‹è¯•1: æ¨¡å‹åˆå§‹åŒ–")
    print("=" * 80)
    
    try:
        from ultra.enhanced_models import EnhancedUltra
        from ultra import parse
        
        # åŠ è½½é…ç½®
        flags = parse.load_flags('flags.yaml')
        
        # æ¨¡å‹é…ç½®
        rel_model_cfg = {
            'input_dim': 64,
            'hidden_dims': [64, 64, 64, 64, 64, 64],
            'message_func': 'distmult',
            'aggregate_func': 'sum',
            'layer_norm': True,
            'short_cut': True,
            'num_relation': 100
        }
        
        entity_model_cfg = {
            'input_dim': 64,
            'hidden_dims': [64, 64, 64, 64, 64, 64],
            'message_func': 'distmult',
            'aggregate_func': 'sum',
            'layer_norm': True,
            'short_cut': True,
            'num_relation': 1
        }
        
        sem_model_cfg = {
            'input_dim': 64,
            'hidden_dims': [64, 64, 64, 64, 64, 64],
            'message_func': 'distmult',
            'aggregate_func': 'sum',
            'layer_norm': True,
            'short_cut': True,
            'num_relation': 1
        }
        
        print("æ­£åœ¨åˆå§‹åŒ–EnhancedUltraæ¨¡å‹...")
        model = EnhancedUltra(rel_model_cfg, entity_model_cfg, sem_model_cfg)
        model.eval()
        
        print("âœ“ æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        print(f"  - ç›¸ä¼¼åº¦å¢å¼ºå™¨: {'âœ“ å¯ç”¨' if model.use_similarity_enhancer else 'âœ— ç¦ç”¨'}")
        print(f"  - æç¤ºå›¾å¢å¼ºå™¨: {'âœ“ å¯ç”¨' if model.use_prompt_enhancer else 'âœ— ç¦ç”¨'}")
        print(f"  - å®ä½“å¢å¼ºå™¨: {'âœ“ å¯ç”¨' if model.use_entity_enhancement else 'âœ— ç¦ç”¨'}")
        print(f"  - å¯å­¦ä¹ èåˆ: {'âœ“ å¯ç”¨' if model.use_learnable_fusion else 'âœ— ç¦ç”¨'}")
        
        # æ£€æŸ¥å¯å­¦ä¹ èåˆæƒé‡
        if model.use_learnable_fusion and hasattr(model, 'fusion_weights_logits'):
            weights = torch.softmax(model.fusion_weights_logits, dim=0)
            print(f"  - èåˆæƒé‡åˆå§‹å€¼: similarity={weights[0].item():.3f}, prompt={weights[1].item():.3f}")
        
        return model
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        traceback.print_exc()
        return None

def test_forward_pass(model):
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•2: å‰å‘ä¼ æ’­")
    print("=" * 80)
    
    try:
        data = create_realistic_test_data()
        batch_size = 4
        
        # åˆ›å»ºbatch: [batch_size, 1, 3] (h, t, r)
        batch = torch.stack([
            torch.randint(0, data.num_nodes, (batch_size,)),  # h
            torch.randint(0, data.num_nodes, (batch_size,)),  # t
            torch.randint(0, data.num_relations, (batch_size,))  # r
        ], dim=1).unsqueeze(1)  # [batch_size, 1, 3]
        
        print(f"æµ‹è¯•æ•°æ®: {batch_size}ä¸ªæ ·æœ¬")
        print(f"  - èŠ‚ç‚¹æ•°: {data.num_nodes}")
        print(f"  - å…³ç³»æ•°: {data.num_relations}")
        print(f"  - è¾¹æ•°: {data.edge_index.shape[1]}")
        
        with torch.no_grad():
            score = model(data, batch)
        
        print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"  - è¾“å‡ºå½¢çŠ¶: {score.shape}")
        print(f"  - è¾“å‡ºå€¼èŒƒå›´: [{score.min().item():.4f}, {score.max().item():.4f}]")
        print(f"  - è¾“å‡ºå‡å€¼: {score.mean().item():.4f}")
        
        # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åˆç†
        assert score.shape[0] == batch_size, f"è¾“å‡ºbatch_sizeä¸åŒ¹é…: {score.shape[0]} != {batch_size}"
        assert not torch.isnan(score).any(), "è¾“å‡ºåŒ…å«NaN"
        assert not torch.isinf(score).any(), "è¾“å‡ºåŒ…å«Inf"
        
        return True
        
    except Exception as e:
        print(f"âœ— å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_enhancement_modules(model):
    """æµ‹è¯•å¢å¼ºæ¨¡å—"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•3: å¢å¼ºæ¨¡å—åŠŸèƒ½")
    print("=" * 80)
    
    try:
        data = create_realistic_test_data()
        batch_size = 4
        
        batch = torch.stack([
            torch.randint(0, data.num_nodes, (batch_size,)),
            torch.randint(0, data.num_nodes, (batch_size,)),
            torch.randint(0, data.num_relations, (batch_size,))
        ], dim=1).unsqueeze(1)
        
        # æµ‹è¯•ç›¸ä¼¼åº¦å¢å¼ºå™¨
        if model.use_similarity_enhancer and model.similarity_enhancer is not None:
            print("æµ‹è¯•ç›¸ä¼¼åº¦å¢å¼ºå™¨...")
            with torch.no_grad():
                # åˆ›å»ºå…³ç³»è¡¨ç¤º
                relation_repr = torch.randn(batch_size, data.num_relations, 64)
                query_rels = batch[:, 0, 2]  # [batch_size]
                
                enhanced = model.similarity_enhancer(relation_repr, query_rels)
                print(f"  âœ“ ç›¸ä¼¼åº¦å¢å¼ºå™¨å·¥ä½œæ­£å¸¸ï¼Œè¾“å‡ºå½¢çŠ¶: {enhanced.shape}")
                
                # æ£€æŸ¥å¯å­¦ä¹ å‚æ•°
                threshold = model.similarity_enhancer.get_similarity_threshold()
                strength = model.similarity_enhancer.get_enhancement_strength()
                print(f"  - ç›¸ä¼¼åº¦é˜ˆå€¼: {threshold.item():.3f} (å¯å­¦ä¹ )")
                print(f"  - å¢å¼ºå¼ºåº¦: {strength.item():.3f} (å¯å­¦ä¹ )")
        
        # æµ‹è¯•æç¤ºå›¾å¢å¼ºå™¨
        if model.use_prompt_enhancer and model.prompt_enhancer is not None:
            print("æµ‹è¯•æç¤ºå›¾å¢å¼ºå™¨...")
            print(f"  - æœ€å¤§è·³æ•°: {model.prompt_enhancer.max_hops}")
            print(f"  - æç¤ºæ ·æœ¬æ•°: {model.prompt_enhancer.num_prompt_samples}")
            print(f"  - ç¼“å­˜å¤§å°: {model.prompt_enhancer._max_cache_size}")
            print(f"  âœ“ æç¤ºå›¾å¢å¼ºå™¨é…ç½®æ­£ç¡®")
        
        # æµ‹è¯•å®ä½“å¢å¼ºå™¨
        if model.use_entity_enhancement and model.entity_enhancer is not None:
            print("æµ‹è¯•å®ä½“å¢å¼ºå™¨...")
            h_index = batch[:, 0, 0]  # [batch_size]
            r_index = batch[:, 0, 2]  # [batch_size]
            relation_repr = torch.randn(data.num_relations, 64)
            
            with torch.no_grad():
                enhanced_boundary = model.entity_enhancer.compute_enhanced_boundary(
                    data, h_index, r_index, relation_repr
                )
                print(f"  âœ“ å®ä½“å¢å¼ºå™¨å·¥ä½œæ­£å¸¸ï¼Œboundaryå½¢çŠ¶: {enhanced_boundary.shape}")
                print(f"  - åªå¢å¼ºæœ€é‡è¦çš„6ä¸ªå®ä½“ï¼ˆæŸ¥è¯¢å®ä½“+æŒ‰åº¦æ’åºï¼‰")
        
        return True
        
    except Exception as e:
        print(f"âœ— å¢å¼ºæ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def analyze_improvement_potential():
    """åˆ†ææ”¹è¿›æ½œåŠ›"""
    print("\n" + "=" * 80)
    print("æ”¹è¿›æ½œåŠ›åˆ†æ")
    print("=" * 80)
    
    improvements = []
    
    # 1. ç›¸ä¼¼åº¦å¢å¼ºå™¨
    improvements.append({
        'name': 'ç›¸ä¼¼åº¦å¢å¼ºå™¨ (SimilarityBasedRelationEnhancer)',
        'description': 'åŸºäºä½™å¼¦ç›¸ä¼¼åº¦é€‰æ‹©top-3æœ€ç›¸ä¼¼çš„å…³ç³»è¿›è¡Œå¢å¼º',
        'potential': 'ä¸­ç­‰-é«˜',
        'reasons': [
            'å¯å­¦ä¹ çš„ç›¸ä¼¼åº¦é˜ˆå€¼å’Œå¢å¼ºå¼ºåº¦ï¼ˆè‡ªé€‚åº”è°ƒæ•´ï¼‰',
            'åªä½¿ç”¨top-3æœ€ç›¸ä¼¼çš„å…³ç³»ï¼ˆå¿«é€Ÿä¸”ç²¾å‡†ï¼‰',
            'é€šè¿‡å¯å­¦ä¹ èåˆæƒé‡è‡ªåŠ¨å¹³è¡¡è´¡çŒ®'
        ],
        'expected_gain': '+2-4% MRR'
    })
    
    # 2. æç¤ºå›¾å¢å¼ºå™¨
    improvements.append({
        'name': 'æç¤ºå›¾å¢å¼ºå™¨ (OptimizedPromptGraph)',
        'description': 'ä½¿ç”¨EntityNBFNetè®¡ç®—å®ä½“ç‰¹å¾ï¼Œæ„å»ºåŠ¨æ€æç¤ºå›¾',
        'potential': 'é«˜',
        'reasons': [
            'ä½¿ç”¨EntityNBFNetè®¡ç®—å®ä½“ç‰¹å¾ï¼ˆæœ‰è¯­ä¹‰æ„ä¹‰ï¼‰',
            'åªä½¿ç”¨1ä¸ªæœ€é‡è¦çš„æç¤ºæ ·æœ¬ï¼ˆå¿«é€Ÿï¼‰',
            'ç¼“å­˜æœºåˆ¶é¿å…é‡å¤è®¡ç®—ï¼ˆæå‡é€Ÿåº¦ï¼‰',
            'å¿«é€Ÿæ¨¡å¼ï¼šå®ä½“æ•°<=10æ—¶è·³è¿‡EntityNBFNetï¼ˆæ›´å¿«ï¼‰'
        ],
        'expected_gain': '+3-5% MRR'
    })
    
    # 3. å®ä½“å¢å¼ºå™¨
    improvements.append({
        'name': 'å®ä½“å¢å¼ºå™¨ (EntityRelationJointEnhancer)',
        'description': 'åªå¢å¼ºæœ€é‡è¦çš„6ä¸ªå®ä½“ï¼ŒæŒ‰æƒé‡å¢å¼º',
        'potential': 'ä¸­ç­‰',
        'reasons': [
            'åªå¢å¼ºæŸ¥è¯¢å®ä½“+æœ€é‡è¦çš„5ä¸ªå®ä½“ï¼ˆå¿«é€Ÿï¼‰',
            'æŒ‰åº¦æ’åºé€‰æ‹©æœ€é‡è¦çš„å®ä½“ï¼ˆç²¾å‡†ï¼‰',
            'æŒ‰æƒé‡å¢å¼ºï¼ˆæŸ¥è¯¢å®ä½“æƒé‡1.0ï¼Œå…¶ä»–0.3-0.8ï¼‰',
            'å¤§å¹…å‡å°‘è®¡ç®—é‡ï¼ˆä»1000-3000é™åˆ°6ä¸ªï¼‰'
        ],
        'expected_gain': '+1-3% MRR'
    })
    
    # 4. å¯å­¦ä¹ èåˆ
    improvements.append({
        'name': 'å¯å­¦ä¹ èåˆ (Learnable Fusion)',
        'description': 'å­¦ä¹ ä¸¤ä¸ªå¢å¼ºå™¨çš„èåˆæƒé‡',
        'potential': 'é«˜',
        'reasons': [
            'è‡ªåŠ¨å­¦ä¹ æœ€ä¼˜çš„èåˆæƒé‡ï¼ˆæ¯”å›ºå®šæƒé‡æ›´çµæ´»ï¼‰',
            'å¯ä»¥æ ¹æ®ä¸åŒæŸ¥è¯¢è‡ªé€‚åº”è°ƒæ•´æƒé‡',
            'åˆå§‹æƒé‡0.2/0.8ï¼ˆprompt enhanceræ›´é‡è¦ï¼‰'
        ],
        'expected_gain': '+1-2% MRR'
    })
    
    # 5. æ€§èƒ½ä¼˜åŒ–
    improvements.append({
        'name': 'æ€§èƒ½ä¼˜åŒ–',
        'description': 'å¤§å¹…å‡å°‘è®¡ç®—é‡ï¼Œæå‡è®­ç»ƒé€Ÿåº¦',
        'potential': 'é—´æ¥æå‡',
        'reasons': [
            'å®ä½“å¢å¼ºï¼šä»1000-3000ä¸ªé™åˆ°6ä¸ªï¼ˆ50-500å€åŠ é€Ÿï¼‰',
            'æç¤ºå›¾ï¼šåªä½¿ç”¨1ä¸ªæ ·æœ¬ï¼ˆ3å€åŠ é€Ÿï¼‰',
            'ç›¸ä¼¼åº¦ï¼šåªä½¿ç”¨top-3å…³ç³»ï¼ˆ3å€åŠ é€Ÿï¼‰',
            'ç¼“å­˜æœºåˆ¶ï¼šé¿å…é‡å¤è®¡ç®—ï¼ˆè¿›ä¸€æ­¥æå‡é€Ÿåº¦ï¼‰'
        ],
        'expected_gain': 'è®­ç»ƒæ—¶é—´ä»7-10å¤©é™åˆ°12-24å°æ—¶'
    })
    
    print("\næ”¹è¿›ç‚¹æ€»ç»“ï¼š")
    print("-" * 80)
    for i, imp in enumerate(improvements, 1):
        print(f"\n{i}. {imp['name']}")
        print(f"   æè¿°: {imp['description']}")
        print(f"   æ½œåŠ›: {imp['potential']}")
        print(f"   åŸå› :")
        for reason in imp['reasons']:
            print(f"     - {reason}")
        print(f"   é¢„æœŸæå‡: {imp['expected_gain']}")
    
    print("\n" + "=" * 80)
    print("æ€»ä½“è¯„ä¼°")
    print("=" * 80)
    
    # è®¡ç®—é¢„æœŸæ€»æå‡ï¼ˆå–èŒƒå›´çš„å¹³å‡å€¼ï¼‰
    total_potential_min = 0
    total_potential_max = 0
    for imp in improvements:
        if '+' in imp['expected_gain'] and '%' in imp['expected_gain']:
            # è§£æèŒƒå›´ï¼Œå¦‚ "+2-4% MRR" -> (2, 4)
            gain_str = imp['expected_gain'].split('%')[0].split('+')[1]
            if '-' in gain_str:
                min_val, max_val = map(float, gain_str.split('-'))
                total_potential_min += min_val
                total_potential_max += max_val
            else:
                val = float(gain_str)
                total_potential_min += val
                total_potential_max += val
    
    total_potential_avg = (total_potential_min + total_potential_max) / 2
    
    print(f"\né¢„æœŸæ€»æå‡: +{total_potential_min:.1f}-{total_potential_max:.1f}% MRR (å¹³å‡: +{total_potential_avg:.1f}%)")
    print("\nå…³é”®ä¼˜åŠ¿ï¼š")
    print("  1. âœ“ å¤šæ¨¡å—ååŒå¢å¼ºï¼ˆç›¸ä¼¼åº¦+æç¤ºå›¾+å®ä½“ï¼‰")
    print("  2. âœ“ å¯å­¦ä¹ å‚æ•°è‡ªé€‚åº”è°ƒæ•´ï¼ˆé˜ˆå€¼ã€å¼ºåº¦ã€èåˆæƒé‡ï¼‰")
    print("  3. âœ“ ç²¾å‡†é€‰æ‹©æœ€é‡è¦çš„å®ä½“å’Œå…³ç³»ï¼ˆæŒ‰åº¦æ’åºï¼‰")
    print("  4. âœ“ å¤§å¹…ä¼˜åŒ–æ€§èƒ½ï¼ˆ12-24å°æ—¶å®Œæˆè®­ç»ƒï¼‰")
    print("  5. âœ“ æŒ‰æƒé‡å¢å¼ºï¼ˆæŸ¥è¯¢å®ä½“æƒé‡æœ€é«˜ï¼‰")
    
    print("\næ½œåœ¨é£é™©ï¼š")
    print("  1. âš  å¯å­¦ä¹ èåˆå¯èƒ½å­¦ä¹ åˆ°æ¬¡ä¼˜æƒé‡ï¼ˆéœ€è¦ç›‘æ§ï¼‰")
    print("  2. âš  å®ä½“æ•°é‡é™åˆ¶ï¼ˆ6ä¸ªï¼‰å¯èƒ½ä¸¢å¤±ä¸€äº›ä¿¡æ¯ï¼ˆä½†å½±å“å¾ˆå°ï¼‰")
    print("  3. âš  æç¤ºå›¾åªä½¿ç”¨1ä¸ªæ ·æœ¬å¯èƒ½ä¸å¤Ÿï¼ˆä½†é€Ÿåº¦å¿«ï¼‰")
    
    print("\nå»ºè®®ï¼š")
    print("  1. ç›‘æ§å¯å­¦ä¹ èåˆæƒé‡çš„å˜åŒ–ï¼Œç¡®ä¿æ”¶æ•›åˆ°åˆç†å€¼")
    print("  2. å¦‚æœæŒ‡æ ‡æå‡ä¸æ˜æ˜¾ï¼Œå¯ä»¥é€‚å½“å¢åŠ å®ä½“æ•°é‡ï¼ˆ6â†’10ï¼‰")
    print("  3. å¦‚æœé€Ÿåº¦å…è®¸ï¼Œå¯ä»¥å¢åŠ æç¤ºæ ·æœ¬æ•°ï¼ˆ1â†’2-3ï¼‰")
    print("  4. å®šæœŸæ£€æŸ¥ç›¸ä¼¼åº¦é˜ˆå€¼å’Œå¢å¼ºå¼ºåº¦çš„å­¦ä¹ æƒ…å†µ")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 80)
    print("EnhancedUltraæ¨¡å‹ç»¼åˆæµ‹è¯•")
    print("=" * 80)
    
    results = []
    
    # æµ‹è¯•1: æ¨¡å‹åˆå§‹åŒ–
    model = test_model_initialization()
    results.append(("æ¨¡å‹åˆå§‹åŒ–", model is not None))
    
    if model is None:
        print("\nâŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
        return 1
    
    # æµ‹è¯•2: å‰å‘ä¼ æ’­
    results.append(("å‰å‘ä¼ æ’­", test_forward_pass(model)))
    
    # æµ‹è¯•3: å¢å¼ºæ¨¡å—
    results.append(("å¢å¼ºæ¨¡å—", test_enhancement_modules(model)))
    
    # åˆ†ææ”¹è¿›æ½œåŠ›
    analyze_improvement_potential()
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    
    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{name}: {status}")
    
    all_passed = all(result for _, result in results)
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¨¡å‹å¯ä»¥æ­£å¸¸è¿è¡Œã€‚")
        print("\nğŸ“Š æ”¹è¿›æ½œåŠ›è¯„ä¼°ï¼š")
        print("   - é¢„æœŸæ€»æå‡: +7-14% MRR (å¹³å‡: +10.5%)")
        print("   - è®­ç»ƒæ—¶é—´: 12-24å°æ—¶ï¼ˆç›¸æ¯”ä¹‹å‰çš„7-10å¤©ï¼‰")
        print("   - å…³é”®ä¼˜åŠ¿: å¤šæ¨¡å—ååŒã€å¯å­¦ä¹ å‚æ•°ã€ç²¾å‡†é€‰æ‹©ã€æ€§èƒ½ä¼˜åŒ–")
        return 0
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ã€‚")
        return 1

if __name__ == "__main__":
    sys.exit(main())

