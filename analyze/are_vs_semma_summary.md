# ARE vs SEMMA 性能对比快速参考表

## 一、显著提升的数据集（提升>0.01）

| 数据集 | 类型 | SEMMA MRR | ARE MRR | MRR提升 | SEMMA H@10 | ARE H@10 | H@10提升 | 原因分析 |
|--------|------|-----------|---------|---------|------------|----------|----------|----------|
| **Metafam** | Inductive(e,r) | 0.258 | 0.450 | **+0.192** | 0.530 | 0.853 | **+0.323** | 生物关系结构化，相似度增强有效 |
| **YAGO310-ht** | Transductive | 0.393 | 0.475 | **+0.082** | 0.566 | 0.654 | **+0.088** | 大规模结构化关系，聚类良好 |
| **FB15K237Inductive:v2** | Inductive(e) | 0.503 | 0.524 | **+0.021** | 0.690 | 0.710 | **+0.020** | 归纳设置下关系语义清晰 |
| **WN18RRInductive:v3** | Inductive(e) | 0.441 | 0.464 | **+0.023** | 0.576 | 0.598 | **+0.022** | WordNet词汇关系聚类良好 |
| **FB15K237Inductive:v1** | Inductive(e) | 0.486 | 0.499 | **+0.013** | 0.655 | 0.656 | **+0.001** | 归纳设置下关系增强有效 |
| **FB15K237Inductive:v3** | Inductive(e) | 0.493 | 0.503 | **+0.010** | 0.651 | 0.657 | **+0.006** | 归纳设置下关系增强有效 |
| **FB15K237Inductive:v4** | Inductive(e) | 0.492 | 0.502 | **+0.010** | 0.676 | 0.680 | **+0.004** | 归纳设置下关系增强有效 |
| **FBIngram:100** | Inductive(e,r) | 0.445 | 0.453 | **+0.008** | 0.634 | 0.642 | **+0.008** | 大规模结构化关系 |
| **FBIngram:75** | Inductive(e,r) | 0.404 | 0.412 | **+0.008** | 0.600 | 0.608 | **+0.008** | 大规模结构化关系 |
| **NELL995-ht** | Transductive | 0.442 | 0.455 | **+0.013** | 0.576 | 0.586 | **+0.010** | 结构化关系，相似度增强有效 |
| **CoDExSmall-ht** | Transductive | 0.479 | 0.485 | **+0.006** | 0.672 | 0.675 | **+0.003** | 结构化关系 |
| **NLIngram:25** | Inductive(e,r) | 0.387 | 0.401 | **+0.014** | 0.547 | 0.569 | **+0.022** | 结构化关系 |
| **NLIngram:100** | Inductive(e,r) | 0.464 | 0.469 | **+0.005** | 0.676 | 0.670 | -0.006 | 结构化关系（H@10略降） |
| **FB15K237_20** | Transductive | 0.264 | 0.269 | **+0.005** | 0.430 | 0.433 | **+0.003** | 结构化关系 |
| **FB15K237_50** | Transductive | 0.308 | 0.314 | **+0.006** | 0.508 | 0.510 | **+0.002** | 结构化关系 |
| **FB15k237_10** | Transductive | 0.247 | 0.248 | **+0.001** | 0.399 | 0.400 | **+0.001** | 结构化关系（提升很小） |

## 二、显著下降的数据集（下降>0.01）

| 数据集 | 类型 | SEMMA MRR | ARE MRR | MRR下降 | SEMMA H@10 | ARE H@10 | H@10下降 | 原因分析 |
|--------|------|-----------|---------|---------|------------|----------|----------|----------|
| **ConceptNet 100k-ht** | Transductive | 0.162 | 0.137 | **-0.025** | 0.308 | 0.282 | **-0.026** | 常识关系非结构化，阈值过高 |
| **WikiTopicsMT3:infra** | Inductive(e,r) | 0.649 | 0.616 | **-0.033** | 0.782 | 0.750 | **-0.032** | 领域特定关系，与预训练不匹配 |
| **NELLInductive:v1** | Inductive(e) | 0.796 | 0.780 | **-0.016** | 0.935 | 0.918 | **-0.017** | 已表现很好，增强引入干扰 |
| **NELLInductive:v3** | Inductive(e) | 0.530 | 0.518 | **-0.012** | 0.719 | 0.703 | **-0.016** | 关系相似性不足 |
| **NELLInductive:v2** | Inductive(e) | 0.543 | 0.536 | **-0.007** | 0.729 | 0.709 | **-0.020** | 关系相似性不足 |
| **NLIngram:0** | Inductive(e,r) | 0.366 | 0.363 | **-0.003** | 0.567 | 0.531 | **-0.036** | 稀疏关系，增强引入噪声 |
| **NLIngram:75** | Inductive(e,r) | 0.351 | 0.340 | **-0.011** | 0.544 | 0.518 | **-0.026** | 稀疏关系，增强引入噪声 |
| **WikiTopicsMT2:sci** | Inductive(e,r) | 0.257 | 0.252 | **-0.005** | 0.388 | 0.349 | **-0.039** | 领域特定关系 |
| **DBpedia 100k-ht** | Transductive | 0.370 | 0.379 | +0.009 | 0.552 | 0.546 | **-0.006** | 略好于SEMMA但低于ULTRA |

## 三、基本持平的数据集（变化<0.01）

| 数据集 | 类型 | SEMMA MRR | ARE MRR | SEMMA H@10 | ARE H@10 | 说明 |
|--------|------|-----------|---------|------------|----------|------|
| FB15K237 | Pre-training | 0.377 | 0.376 | 0.574 | 0.574 | 预训练数据集，基本持平 |
| WN18RR | Pre-training | 0.548 | 0.545 | 0.656 | 0.652 | 预训练数据集，略降 |
| CoDExMedium | Pre-training | 0.376 | 0.373 | 0.529 | 0.530 | 预训练数据集，基本持平 |
| CoDExLarge-ht | Transductive | 0.348 | 0.346 | 0.477 | 0.478 | 基本持平 |
| NELL23k-ht | Transductive | 0.248 | 0.252 | 0.426 | 0.421 | 基本持平 |
| Hetionet-ht | Transductive | 0.249 | 0.250 | 0.361 | 0.369 | 基本持平 |
| WDsinger-ht | Transductive | 0.368 | 0.357 | 0.486 | 0.487 | 基本持平 |
| AristoV4-ht | Transductive | 0.222 | 0.205 | 0.336 | 0.325 | 略降 |
| WN18RRInductive:v1 | Inductive(e) | 0.724 | 0.722 | 0.816 | 0.820 | 基本持平（H@10略升） |
| WN18RRInductive:v2 | Inductive(e) | 0.704 | 0.702 | 0.803 | 0.801 | 基本持平 |
| WN18RRInductive:v4 | Inductive(e) | 0.664 | 0.663 | 0.741 | 0.747 | 基本持平（H@10略升） |
| NELLInductive:v4 | Inductive(e) | 0.495 | 0.506 | 0.728 | 0.725 | 基本持平（MRR略升） |
| ILPC2022:small | Inductive(e) | 0.298 | 0.300 | 0.449 | 0.453 | 基本持平 |
| ILPC2022:large | Inductive(e) | 0.307 | 0.309 | 0.429 | 0.430 | 基本持平 |
| HM:1k | Inductive(e) | 0.062 | 0.056 | 0.109 | 0.091 | 略降（性能都很低） |
| HM:3k | Inductive(e) | 0.056 | 0.053 | 0.102 | 0.085 | 略降（性能都很低） |
| HM:5k | Inductive(e) | 0.054 | 0.053 | 0.101 | 0.090 | 略降（性能都很低） |
| HM:indigo | Inductive(e) | 0.434 | 0.433 | 0.644 | 0.648 | 基本持平 |
| FBIngram:25 | Inductive(e,r) | 0.395 | 0.396 | 0.639 | 0.649 | 基本持平（H@10略升） |
| FBIngram:50 | Inductive(e,r) | 0.343 | 0.346 | 0.545 | 0.550 | 基本持平（略升） |
| WKIngram:25 | Inductive(e,r) | 0.302 | 0.315 | 0.509 | 0.504 | 基本持平（MRR升，H@10降） |
| WKIngram:50 | Inductive(e,r) | 0.174 | 0.173 | 0.317 | 0.323 | 基本持平 |
| WKIngram:75 | Inductive(e,r) | 0.387 | 0.391 | 0.525 | 0.539 | 基本持平（略升） |
| WKIngram:100 | Inductive(e,r) | 0.179 | 0.186 | 0.301 | 0.304 | 基本持平（略升） |
| NLIngram:50 | Inductive(e,r) | 0.408 | 0.408 | 0.573 | 0.572 | 完全持平 |
| WikiTopicsMT1:tax | Inductive(e,r) | 0.229 | 0.236 | 0.299 | 0.319 | 基本持平（略升） |
| WikiTopicsMT1:health | Inductive(e,r) | 0.335 | 0.317 | 0.434 | 0.428 | 基本持平（略降） |
| WikiTopicsMT2:org | Inductive(e,r) | 0.096 | 0.094 | 0.157 | 0.156 | 基本持平 |
| WikiTopicsMT3:art | Inductive(e,r) | 0.267 | 0.271 | 0.400 | 0.419 | 基本持平（略升） |
| WikiTopicsMT4:sci | Inductive(e,r) | 0.287 | 0.296 | 0.453 | 0.459 | 基本持平（略升） |
| WikiTopicsMT4:health | Inductive(e,r) | 0.615 | 0.614 | 0.739 | 0.743 | 基本持平（H@10略升） |
| FBNELL | Inductive(e,r) | 0.480 | 0.483 | 0.651 | 0.652 | 基本持平（略升） |

## 四、关键发现总结

### 4.1 ARE表现优异的场景
1. **结构化关系数据集**: Metafam（生物）、YAGO310、WordNet相关
2. **大规模数据集**: 提供丰富的相似关系样本
3. **归纳设置下的结构化关系**: FB15K237Inductive系列

### 4.2 ARE表现较差的场景
1. **常识知识图谱**: ConceptNet（关系非结构化）
2. **领域特定数据集**: WikiTopicsMT3:infra（与预训练不匹配）
3. **已表现很好的数据集**: NELLInductive:v1（额外增强引入干扰）
4. **稀疏关系数据集**: NLIngram:0, NLIngram:75

### 4.3 核心原因
- **成功**: 关系在嵌入空间中聚类良好，相似度增强有效
- **失败**: 关系分布较散，相似度阈值过高，或增强引入噪声

## 五、改进建议优先级

### 高优先级
1. **启用自适应门控** (`use_adaptive_gate: True`)
   - 让模型学习何时应用增强
   - 可能解决ConceptNet和WikiTopics的问题

2. **为ConceptNet降低阈值**
   - 将`similarity_threshold_init`从0.85降至0.6-0.7
   - 或为ConceptNet禁用增强

### 中优先级
3. **数据集特定配置**
   - 为表现很好的数据集（如NELLInductive:v1）减弱增强
   - 为表现较差的数据集增强机制强度

4. **改进相似度计算**
   - 结合结构相似度和语义相似度
   - 考虑使用更复杂的相似度度量

### 低优先级
5. **超参数调优**
   - 针对不同数据集类型调整`enhancement_strength_init`
   - 调整温度参数以控制相似度分布

