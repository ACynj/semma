"""
åˆ†ææ¯ä¸ªæµ‹è¯•æ ·æœ¬çš„ç›¸ä¼¼å…³ç³»å‚è€ƒæƒ…å†µ
ç»Ÿè®¡æœ‰å¤šå°‘å¯ä»¥å‚è€ƒçš„ã€æœ‰å¤šå°‘æ˜¯æœ‰æ•ˆçš„ã€å¤šå°‘å¼•å…¥äº†å™ªéŸ³
"""

import os
import sys
import yaml
import torch
import numpy as np
import pandas as pd
from pathlib import Path
from collections import defaultdict
from types import SimpleNamespace
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ultra import datasets, util, parse
from ultra.models import Ultra
from ultra.enhanced_models import EnhancedUltra
from torch_geometric.data import Data
import torch.nn.functional as F

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def load_flags():
    """åŠ è½½flags.yamlé…ç½®"""
    flags_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "flags.yaml")
    with open(flags_path, 'r', encoding='utf-8') as f:
        flags = yaml.safe_load(f)
    return flags

def load_dataset(dataset_name, dataset_type="transductive"):
    """åŠ è½½æ•°æ®é›†"""
    flags = load_flags()
    
    # å¤„ç†æ•°æ®é›†åç§°æ˜ å°„
    dataset_name_mapping = {
        'NELL995-ht': 'NELL995',
        'YAGO310-ht': 'YAGO310',
        'ConceptNet 100k-ht': 'ConceptNet100k',
        'WDsinger-ht': 'WDsinger',
        'AristoV4-ht': 'AristoV4',
        'FB15K237Inductive:v1': 'FB15k237Inductive',  # æ³¨æ„ï¼šå°å†™k
        'FB15K237Inductive:v2': 'FB15k237Inductive',
        'FB15K237Inductive:v3': 'FB15k237Inductive',
        'NELLInductive:v1': 'NELLInductive',
        'NELLInductive:v3': 'NELLInductive',
    }
    
    # è·å–å®é™…çš„æ•°æ®é›†ç±»å
    actual_dataset_name = dataset_name_mapping.get(dataset_name, dataset_name)
    
    # å¤„ç†ç‰ˆæœ¬å·
    version = None
    if ':' in dataset_name:
        parts = dataset_name.split(':')
        if len(parts) == 2:
            # å¦‚æœå·²ç»åœ¨mappingä¸­ï¼Œä¸è¦è¦†ç›–
            if dataset_name not in dataset_name_mapping:
                actual_dataset_name = parts[0]
            version = parts[1]
    
    # è·å–æ•°æ®é›†è·¯å¾„
    kg_datasets_path = flags.get('kg_datasets_path', '/T20030104/ynj/semma/kg-datasets')
    
    # æ„å»ºé…ç½®
    # rootå‚æ•°åº”è¯¥æ˜¯kg_datasets_pathï¼ˆæ•°æ®é›†ä¼šè‡ªåŠ¨æ ¹æ®nameåœ¨kg_datasets_pathä¸‹æŸ¥æ‰¾ï¼‰
    # æ ¹æ®é…ç½®æ–‡ä»¶ï¼Œrootç›´æ¥è®¾ç½®ä¸ºkg_datasets_path
    cfg = {
        'dataset': {
            'class': actual_dataset_name,
            'root': kg_datasets_path,  # ä½¿ç”¨kg_datasets_pathä½œä¸ºroot
        },
        'task': {
            'name': 'InductiveInference' if dataset_type != 'transductive' else 'LinkPrediction'
        }
    }
    
    # å¦‚æœæœ‰ç‰ˆæœ¬å·ï¼Œæ·»åŠ åˆ°é…ç½®ä¸­
    if version:
        cfg['dataset']['version'] = version
    
    try:
        # å°†å­—å…¸è½¬æ¢ä¸ºå¯¹è±¡ï¼Œä»¥ä¾¿ build_dataset å¯ä»¥è®¿é—® cfg.dataset
        cfg_obj = SimpleNamespace()
        cfg_obj.dataset = cfg['dataset']
        cfg_obj.task = cfg.get('task', {})
        
        dataset = util.build_dataset(cfg_obj)
        # æ•°æ®é›†é€šè¿‡ç´¢å¼•è®¿é—®ï¼šdataset[0] = train, dataset[1] = valid, dataset[2] = test
        train_data = dataset[0]
        valid_data = dataset[1]
        test_data = dataset[2]
        return dataset, train_data, valid_data, test_data
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®é›†å¤±è´¥ {dataset_name} (å®é™…ç±»å: {actual_dataset_name}): {e}")
        import traceback
        traceback.print_exception(*sys.exc_info())
        return None, None, None, None

def load_model(checkpoint_path, dataset, device):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    flags = load_flags()
    
    # AREå°±æ˜¯EnhanceUltraæ¨¡å‹ï¼Œæ‰€ä»¥ä½¿ç”¨EnhancedUltra
    # ä½†ä¹Ÿè¦æ£€æŸ¥flagsä¸­çš„è®¾ç½®
    model_type = flags.get('run', 'semma')
    
    # å¦‚æœflagsä¸­ä¸æ˜¯EnhancedUltraï¼Œä½†æˆ‘ä»¬è¦åˆ†æAREï¼Œåˆ™ä½¿ç”¨EnhancedUltra
    # å› ä¸ºç”¨æˆ·æ˜ç¡®è¯´AREæŒ‡çš„æ˜¯EnhanceUltraæ¨¡å‹
    use_enhanced = True  # åˆ†æAREï¼Œæ‰€ä»¥æ€»æ˜¯ä½¿ç”¨EnhancedUltra
    
    # ä½¿ç”¨é…ç½®æ„å»ºæ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…åº”è¯¥ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
    # è¿™é‡Œæˆ‘ä»¬å°è¯•ç›´æ¥åŠ è½½checkpointï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
    model = None
    
    # å°è¯•åŠ è½½checkpoint
    if checkpoint_path and os.path.exists(checkpoint_path):
        try:
            state = torch.load(checkpoint_path, map_location='cpu')
            
            # å°è¯•ä»stateä¸­æ¨æ–­æ¨¡å‹ç»“æ„
            if 'model' in state:
                state_dict = state['model']
            else:
                state_dict = state
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯EnhancedUltraï¼ˆAREå°±æ˜¯EnhanceUltraï¼‰
            if 'similarity_enhancer' in state_dict or use_enhanced or model_type == 'EnhancedUltra':
                from ultra.enhanced_models import EnhancedUltra
                # éœ€è¦ä»state_dictæ¨æ–­é…ç½®ï¼Œè¿™é‡Œä½¿ç”¨é»˜è®¤é…ç½®
                model = EnhancedUltra(
                    rel_model_cfg={'class': 'RelNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64], 'num_relations': dataset[0].num_relations},
                    entity_model_cfg={'class': 'EntityNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64]},
                    sem_model_cfg={'class': 'SemRelNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64], 'num_relations': dataset[0].num_relations}
                )
            else:
                from ultra.models import Ultra
                model = Ultra(
                    rel_model_cfg={'class': 'RelNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64], 'num_relations': dataset[0].num_relations},
                    entity_model_cfg={'class': 'EntityNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64]},
                    sem_model_cfg={'class': 'SemRelNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64], 'num_relations': dataset[0].num_relations}
                )
            
            # åŠ è½½æƒé‡
            if 'model' in state:
                model.load_state_dict(state['model'], strict=False)
            else:
                model.load_state_dict(state, strict=False)
            print(f"âœ… åŠ è½½æ¨¡å‹checkpoint: {checkpoint_path}")
        except Exception as e:
            print(f"âš ï¸  åŠ è½½checkpointå¤±è´¥: {e}ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹")
            # å¦‚æœåŠ è½½å¤±è´¥ï¼Œåˆ›å»ºé»˜è®¤æ¨¡å‹ï¼ˆä½¿ç”¨EnhancedUltraï¼Œå› ä¸ºAREå°±æ˜¯EnhanceUltraï¼‰
            if use_enhanced or model_type == 'EnhancedUltra':
                from ultra.enhanced_models import EnhancedUltra
                model = EnhancedUltra(
                    rel_model_cfg={'class': 'RelNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64], 'num_relations': dataset[0].num_relations},
                    entity_model_cfg={'class': 'EntityNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64]},
                    sem_model_cfg={'class': 'SemRelNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64], 'num_relations': dataset[0].num_relations}
                )
            else:
                from ultra.models import Ultra
                model = Ultra(
                    rel_model_cfg={'class': 'RelNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64], 'num_relations': dataset[0].num_relations},
                    entity_model_cfg={'class': 'EntityNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64]},
                    sem_model_cfg={'class': 'SemRelNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64], 'num_relations': dataset[0].num_relations}
                )
    else:
        print(f"âš ï¸  Checkpointä¸å­˜åœ¨: {checkpoint_path}ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹")
        # åˆ›å»ºé»˜è®¤æ¨¡å‹ï¼ˆä½¿ç”¨EnhancedUltraï¼Œå› ä¸ºAREå°±æ˜¯EnhanceUltraï¼‰
        if use_enhanced or model_type == 'EnhancedUltra':
            from ultra.enhanced_models import EnhancedUltra
            model = EnhancedUltra(
                rel_model_cfg={'class': 'RelNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64], 'num_relations': dataset[0].num_relations},
                entity_model_cfg={'class': 'EntityNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64]},
                sem_model_cfg={'class': 'SemRelNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64], 'num_relations': dataset[0].num_relations}
            )
        else:
            from ultra.models import Ultra
            model = Ultra(
                rel_model_cfg={'class': 'RelNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64], 'num_relations': dataset[0].num_relations},
                entity_model_cfg={'class': 'EntityNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64]},
                sem_model_cfg={'class': 'SemRelNBFNet', 'input_dim': 64, 'hidden_dims': [64, 64], 'num_relations': dataset[0].num_relations}
            )
    
    model = model.to(device)
    model.eval()
    return model

def find_similar_relations(model, data, query_rel_idx, threshold=0.8, device='cuda'):
    """
    æ‰¾åˆ°ä¸æŸ¥è¯¢å…³ç³»ç›¸ä¼¼çš„å…³ç³»
    
    Returns:
        similar_rels: list of (rel_idx, similarity) tuples
    """
    model.eval()
    with torch.no_grad():
        try:
            # ç¡®ä¿dataåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            if hasattr(data, 'to'):
                data = data.to(device)
            elif hasattr(data, 'keys'):
                # å¦‚æœdataæ˜¯Dataå¯¹è±¡ï¼Œéœ€è¦ç§»åŠ¨æ‰€æœ‰tensorå±æ€§
                for key in data.keys:
                    if isinstance(getattr(data, key), torch.Tensor):
                        setattr(data, key, getattr(data, key).to(device))
            # å¦‚æœdataå·²ç»æ˜¯torch_geometric.data.Dataå¯¹è±¡ï¼Œå®ƒåº”è¯¥å·²ç»æœ‰toæ–¹æ³•
            
            # è·å–å…³ç³»è¡¨ç¤º
            query_rels = torch.tensor([query_rel_idx], device=device)
            
            # è·å–å…³ç³»è¡¨ç¤º - å¯¹äºUltraå’ŒEnhancedUltraæ¨¡å‹
            if hasattr(model, 'relation_model'):
                relation_reprs = model.relation_model(data, query=query_rels)
            elif hasattr(model, 'model') and hasattr(model.model, 'relation_model'):
                # å¯¹äºUltraQueryç­‰åŒ…è£…æ¨¡å‹
                relation_reprs = model.model.relation_model(data, query=query_rels)
            else:
                return []
            
            if relation_reprs is None or relation_reprs.shape[0] == 0:
                return []
            
            # relation_reprs shape: [batch_size, num_relations, embedding_dim]
            # è·å–æŸ¥è¯¢å…³ç³»çš„è¡¨ç¤º
            query_repr = relation_reprs[0, query_rel_idx, :]  # [embedding_dim]
            all_reprs = relation_reprs[0, :, :]  # [num_relations, embedding_dim]
            
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            query_norm = F.normalize(query_repr, p=2, dim=0)
            all_norms = F.normalize(all_reprs, p=2, dim=1)
            similarities = torch.matmul(query_norm.unsqueeze(0), all_norms.t()).squeeze(0)
            
            # æ’é™¤æŸ¥è¯¢å…³ç³»æœ¬èº«
            similarities[query_rel_idx] = -1.0
            
            # æ‰¾åˆ°ç›¸ä¼¼åº¦å¤§äºé˜ˆå€¼çš„å…³ç³»
            above_threshold = similarities > threshold
            valid_indices = torch.where(above_threshold)[0]
            
            similar_rels = [(idx.item(), similarities[idx].item()) for idx in valid_indices]
            similar_rels.sort(key=lambda x: x[1], reverse=True)
            
            return similar_rels
        except Exception as e:
            print(f"âš ï¸  æŸ¥æ‰¾ç›¸ä¼¼å…³ç³»æ—¶å‡ºé”™: {e}")
            return []

def check_reference_effectiveness(similar_rels, train_triples, test_triple, entity_vocab, relation_vocab):
    """
    æ£€æŸ¥ç›¸ä¼¼å…³ç³»çš„æœ‰æ•ˆæ€§
    
    Args:
        similar_rels: list of (rel_idx, similarity) tuples
        train_triples: list of (h, r, t) tuples from training data
        test_triple: (h, r, t) tuple from test data
        entity_vocab: entity vocabulary
        relation_vocab: relation vocabulary
    
    Returns:
        effective_refs: list of effective reference relations
        noise_refs: list of noise reference relations
    """
    test_h, test_r, test_t = test_triple
    
    # æ„å»ºè®­ç»ƒæ•°æ®çš„å…³ç³»-å®ä½“å¯¹é›†åˆï¼ˆç”¨äºå¿«é€ŸæŸ¥æ‰¾ï¼‰
    # å¯¹äºtailé¢„æµ‹ï¼š(h, r) -> {t1, t2, ...}
    # å¯¹äºheadé¢„æµ‹ï¼š(r, t) -> {h1, h2, ...}
    train_tail_contexts = defaultdict(set)  # (h, r) -> {tails}
    train_head_contexts = defaultdict(set)  # (r, t) -> {heads}
    
    for h, r, t in train_triples:
        train_tail_contexts[(h, r)].add(t)
        train_head_contexts[(r, t)].add(h)
    
    effective_refs = []
    noise_refs = []
    
    # æ£€æŸ¥æ¯ä¸ªç›¸ä¼¼å…³ç³»
    for rel_idx, similarity in similar_rels:
        # æ£€æŸ¥è¿™ä¸ªç›¸ä¼¼å…³ç³»æ˜¯å¦åœ¨è®­ç»ƒæ•°æ®ä¸­å‡ºç°ï¼Œå¹¶ä¸”èƒ½å¸®åŠ©é¢„æµ‹
        # å¯¹äºtailé¢„æµ‹ï¼šæ£€æŸ¥(h, similar_rel)æ˜¯å¦åœ¨è®­ç»ƒæ•°æ®ä¸­å‡ºç°
        # å¯¹äºheadé¢„æµ‹ï¼šæ£€æŸ¥(similar_rel, t)æ˜¯å¦åœ¨è®­ç»ƒæ•°æ®ä¸­å‡ºç°
        
        # Tailé¢„æµ‹æœ‰æ•ˆæ€§
        tail_effective = False
        if (test_h, rel_idx) in train_tail_contexts:
            # å¦‚æœç›¸ä¼¼å…³ç³»åœ¨è®­ç»ƒæ•°æ®ä¸­å‡ºç°ï¼Œå¹¶ä¸”é¢„æµ‹çš„tailä¹Ÿåœ¨å…¶ä¸­ï¼Œåˆ™æœ‰æ•ˆ
            if test_t in train_tail_contexts[(test_h, rel_idx)]:
                tail_effective = True
            # æˆ–è€…ï¼Œå¦‚æœç›¸ä¼¼å…³ç³»åœ¨è®­ç»ƒæ•°æ®ä¸­å‡ºç°ï¼Œå³ä½¿é¢„æµ‹çš„tailä¸åœ¨å…¶ä¸­ï¼Œä¹Ÿå¯èƒ½æœ‰å¸®åŠ©
            elif len(train_tail_contexts[(test_h, rel_idx)]) > 0:
                tail_effective = True  # è‡³å°‘æä¾›äº†ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        # Headé¢„æµ‹æœ‰æ•ˆæ€§
        head_effective = False
        if (rel_idx, test_t) in train_head_contexts:
            if test_h in train_head_contexts[(rel_idx, test_t)]:
                head_effective = True
            elif len(train_head_contexts[(rel_idx, test_t)]) > 0:
                head_effective = True
        
        if tail_effective or head_effective:
            effective_refs.append((rel_idx, similarity, 'tail' if tail_effective else 'head'))
        else:
            noise_refs.append((rel_idx, similarity))
    
    return effective_refs, noise_refs

def find_checkpoint_path(dataset_name, base_checkpoint='ckpts/optuna_1.pth'):
    """
    æŸ¥æ‰¾æ•°æ®é›†çš„checkpointè·¯å¾„
    
    Args:
        dataset_name: æ•°æ®é›†åç§°
        base_checkpoint: åŸºç¡€checkpointè·¯å¾„
    
    Returns:
        checkpoint_path: checkpointè·¯å¾„
    """
    flags = load_flags()
    base_path = flags.get('base_path', '/T20030104/ynj/semma')
    
    # é¦–å…ˆå°è¯•ä½¿ç”¨åŸºç¡€checkpoint
    base_ckpt_path = os.path.join(base_path, base_checkpoint)
    if os.path.exists(base_ckpt_path):
        return base_ckpt_path
    
    # å°è¯•åœ¨optuna_1_outputä¸­æŸ¥æ‰¾æ•°æ®é›†ç‰¹å®šçš„checkpoint
    output_dir = os.path.join(base_path, 'optuna_1_output', 'Ultra')
    
    # æ•°æ®é›†åç§°æ˜ å°„
    dataset_name_mapping = {
        'NELL995-ht': 'NELL995',
        'YAGO310-ht': 'YAGO310',
        'ConceptNet 100k-ht': 'ConceptNet100k',
        'WDsinger-ht': 'WDsinger',
        'AristoV4-ht': 'AristoV4',
        'FB15K237Inductive:v1': 'FB15k237Inductive',
        'FB15K237Inductive:v2': 'FB15k237Inductive',
        'FB15K237Inductive:v3': 'FB15k237Inductive',
        'NELLInductive:v1': 'NELLInductive',
        'NELLInductive:v3': 'NELLInductive',
    }
    
    mapped_name = dataset_name_mapping.get(dataset_name, dataset_name)
    
    # æŸ¥æ‰¾æ•°æ®é›†æ–‡ä»¶å¤¹
    dataset_output_dir = os.path.join(output_dir, mapped_name)
    if os.path.exists(dataset_output_dir):
        # æŸ¥æ‰¾æœ€æ–°çš„checkpointæ–‡ä»¶
        import glob
        ckpt_files = glob.glob(os.path.join(dataset_output_dir, '**', '*.pth'), recursive=True)
        if ckpt_files:
            # è¿”å›æœ€æ–°çš„checkpoint
            ckpt_files.sort(key=os.path.getmtime, reverse=True)
            return ckpt_files[0]
    
    # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›åŸºç¡€checkpointè·¯å¾„ï¼ˆå³ä½¿ä¸å­˜åœ¨ï¼‰
    return base_ckpt_path

def analyze_dataset_samples(dataset_name, dataset_type, checkpoint_path=None, num_samples=1000, device='cuda'):
    """
    åˆ†ææ•°æ®é›†æ ·æœ¬çº§åˆ«çš„ç›¸ä¼¼å…³ç³»å‚è€ƒæƒ…å†µ
    
    Args:
        dataset_name: æ•°æ®é›†åç§°
        dataset_type: æ•°æ®é›†ç±»å‹
        checkpoint_path: æ¨¡å‹checkpointè·¯å¾„ï¼ˆå¦‚æœä¸ºNoneï¼Œä¼šè‡ªåŠ¨æŸ¥æ‰¾ï¼‰
        num_samples: åˆ†æçš„æ ·æœ¬æ•°é‡
        device: è®¾å¤‡
    """
    print(f"\n{'='*70}")
    print(f"ğŸ“Š åˆ†ææ•°æ®é›†: {dataset_name} ({dataset_type})")
    print(f"{'='*70}")
    
    # åŠ è½½æ•°æ®é›†
    dataset, train_data, valid_data, test_data = load_dataset(dataset_name, dataset_type)
    if dataset is None:
        return None
    
    # æŸ¥æ‰¾checkpointè·¯å¾„
    if checkpoint_path is None:
        checkpoint_path = find_checkpoint_path(dataset_name)
        print(f"ğŸ“ ä½¿ç”¨checkpoint: {checkpoint_path}")
    
    # åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨EnhancedUltraï¼Œå› ä¸ºAREå°±æ˜¯EnhanceUltraï¼‰
    model = load_model(checkpoint_path, dataset, device)
    
    # ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
    test_data = test_data.to(device)
    train_data = train_data.to(device)
    
    # è·å–æµ‹è¯•ä¸‰å…ƒç»„
    test_triplets = torch.cat([test_data.target_edge_index, test_data.target_edge_type.unsqueeze(0)]).t()
    
    # é™åˆ¶æ ·æœ¬æ•°é‡
    if len(test_triplets) > num_samples:
        indices = torch.randperm(len(test_triplets))[:num_samples]
        test_triplets = test_triplets[indices]
    
    # è·å–è®­ç»ƒä¸‰å…ƒç»„ï¼ˆç”¨äºæœ‰æ•ˆæ€§æ£€æŸ¥ï¼‰
    train_triplets = torch.cat([train_data.edge_index, train_data.edge_type.unsqueeze(0)]).t()
    train_triples_list = [(int(h.item()), int(r.item()), int(t.item())) for h, r, t in train_triplets]
    
    # æ„å»ºå®ä½“å’Œå…³ç³»è¯æ±‡è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼Œä½¿ç”¨ç´¢å¼•ï¼‰
    num_entities = dataset[0].num_nodes
    num_relations = dataset[0].num_relations
    entity_vocab = {i: i for i in range(num_entities)}
    relation_vocab = {i: i for i in range(num_relations)}
    
    # ç»Ÿè®¡æ•°æ®
    stats = {
        'total_samples': 0,
        'samples_with_references': 0,
        'total_references': 0,
        'effective_references': 0,
        'noise_references': 0,
        'samples_with_effective_refs': 0,
        'samples_with_only_noise': 0,
    }
    
    sample_results = []
    
    # è·å–ç›¸ä¼¼åº¦é˜ˆå€¼
    flags = load_flags()
    threshold = flags.get('similarity_threshold_init', 0.8)
    
    print(f"\nğŸ” åˆ†æ {len(test_triplets)} ä¸ªæµ‹è¯•æ ·æœ¬...")
    
    for i, triplet in enumerate(tqdm(test_triplets, desc="åˆ†ææ ·æœ¬")):
        h, t, r = int(triplet[0]), int(triplet[1]), int(triplet[2])
        
        stats['total_samples'] += 1
        
        # æ‰¾åˆ°ç›¸ä¼¼å…³ç³»ï¼ˆtest_dataå·²ç»åœ¨deviceä¸Šäº†ï¼‰
        similar_rels = find_similar_relations(model, test_data, r, threshold=threshold, device=device)
        
        if len(similar_rels) == 0:
            sample_results.append({
                'sample_idx': i,
                'test_triple': (h, r, t),
                'num_references': 0,
                'num_effective': 0,
                'num_noise': 0,
                'has_references': False,
                'has_effective_refs': False,
                'has_only_noise': False,
            })
            continue
        
        stats['samples_with_references'] += 1
        stats['total_references'] += len(similar_rels)
        
        # æ£€æŸ¥æœ‰æ•ˆæ€§
        effective_refs, noise_refs = check_reference_effectiveness(
            similar_rels, train_triples_list, (h, r, t), entity_vocab, relation_vocab
        )
        
        stats['effective_references'] += len(effective_refs)
        stats['noise_references'] += len(noise_refs)
        
        if len(effective_refs) > 0:
            stats['samples_with_effective_refs'] += 1
        
        if len(effective_refs) == 0 and len(noise_refs) > 0:
            stats['samples_with_only_noise'] += 1
        
        sample_results.append({
            'sample_idx': i,
            'test_triple': (h, r, t),
            'num_references': len(similar_rels),
            'num_effective': len(effective_refs),
            'num_noise': len(noise_refs),
            'has_references': True,
            'has_effective_refs': len(effective_refs) > 0,
            'has_only_noise': len(effective_refs) == 0 and len(noise_refs) > 0,
            'effective_refs': effective_refs,
            'noise_refs': noise_refs,
        })
    
    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    if stats['total_samples'] > 0:
        stats['reference_rate'] = stats['samples_with_references'] / stats['total_samples']
        stats['effective_rate'] = stats['samples_with_effective_refs'] / stats['total_samples']
        stats['noise_rate'] = stats['samples_with_only_noise'] / stats['total_samples']
    
    if stats['total_references'] > 0:
        stats['reference_effectiveness'] = stats['effective_references'] / stats['total_references']
        stats['reference_noise_ratio'] = stats['noise_references'] / stats['total_references']
    
    # æ‰“å°ç»Ÿè®¡ç»“æœ
    print(f"\nğŸ“ˆ ç»Ÿè®¡ç»“æœ:")
    print(f"  æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
    print(f"  æœ‰å‚è€ƒçš„æ ·æœ¬æ•°: {stats['samples_with_references']} ({stats.get('reference_rate', 0)*100:.2f}%)")
    print(f"  æ€»å‚è€ƒæ•°: {stats['total_references']}")
    print(f"  æœ‰æ•ˆå‚è€ƒæ•°: {stats['effective_references']} ({stats.get('reference_effectiveness', 0)*100:.2f}%)")
    print(f"  å™ªéŸ³å‚è€ƒæ•°: {stats['noise_references']} ({stats.get('reference_noise_ratio', 0)*100:.2f}%)")
    print(f"  æœ‰æœ‰æ•ˆå‚è€ƒçš„æ ·æœ¬æ•°: {stats['samples_with_effective_refs']} ({stats.get('effective_rate', 0)*100:.2f}%)")
    print(f"  åªæœ‰å™ªéŸ³çš„æ ·æœ¬æ•°: {stats['samples_with_only_noise']} ({stats.get('noise_rate', 0)*100:.2f}%)")
    
    return {
        'dataset_name': dataset_name,
        'dataset_type': dataset_type,
        'stats': stats,
        'sample_results': sample_results,
    }

def visualize_results(all_results, output_dir='analyze/figures'):
    """å¯è§†åŒ–åˆ†æç»“æœ"""
    os.makedirs(output_dir, exist_ok=True)
    
    # å‡†å¤‡æ•°æ®
    datasets = []
    reference_rates = []
    effectiveness_rates = []
    noise_rates = []
    
    for result in all_results:
        if result is None:
            continue
        datasets.append(result['dataset_name'])
        stats = result['stats']
        reference_rates.append(stats.get('reference_rate', 0) * 100)
        effectiveness_rates.append(stats.get('reference_effectiveness', 0) * 100)
        noise_rates.append(stats.get('reference_noise_ratio', 0) * 100)
    
    if len(datasets) == 0:
        print("âš ï¸  æ²¡æœ‰æ•°æ®å¯å¯è§†åŒ–")
        return
    
    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. å‚è€ƒç‡å¯¹æ¯”
    ax1 = axes[0, 0]
    bars1 = ax1.bar(range(len(datasets)), reference_rates, color='skyblue')
    ax1.set_xlabel('Dataset', fontsize=12)
    ax1.set_ylabel('Reference Rate (%)', fontsize=12)
    ax1.set_title('Percentage of Samples with References', fontsize=14, fontweight='bold')
    ax1.set_xticks(range(len(datasets)))
    ax1.set_xticklabels(datasets, rotation=45, ha='right')
    ax1.grid(axis='y', alpha=0.3)
    for i, v in enumerate(reference_rates):
        ax1.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom', fontsize=9)
    
    # 2. æœ‰æ•ˆæ€§ç‡å¯¹æ¯”
    ax2 = axes[0, 1]
    bars2 = ax2.bar(range(len(datasets)), effectiveness_rates, color='lightgreen')
    ax2.set_xlabel('Dataset', fontsize=12)
    ax2.set_ylabel('Effectiveness Rate (%)', fontsize=12)
    ax2.set_title('Percentage of Effective References', fontsize=14, fontweight='bold')
    ax2.set_xticks(range(len(datasets)))
    ax2.set_xticklabels(datasets, rotation=45, ha='right')
    ax2.grid(axis='y', alpha=0.3)
    for i, v in enumerate(effectiveness_rates):
        ax2.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom', fontsize=9)
    
    # 3. å™ªéŸ³ç‡å¯¹æ¯”
    ax3 = axes[1, 0]
    bars3 = ax3.bar(range(len(datasets)), noise_rates, color='lightcoral')
    ax3.set_xlabel('Dataset', fontsize=12)
    ax3.set_ylabel('Noise Rate (%)', fontsize=12)
    ax3.set_title('Percentage of Noise References', fontsize=14, fontweight='bold')
    ax3.set_xticks(range(len(datasets)))
    ax3.set_xticklabels(datasets, rotation=45, ha='right')
    ax3.grid(axis='y', alpha=0.3)
    for i, v in enumerate(noise_rates):
        ax3.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom', fontsize=9)
    
    # 4. ç»¼åˆå¯¹æ¯”ï¼ˆå †å æŸ±çŠ¶å›¾ï¼‰
    ax4 = axes[1, 1]
    x = np.arange(len(datasets))
    width = 0.6
    effective_bars = ax4.bar(x, effectiveness_rates, width, label='Effective', color='lightgreen')
    noise_bars = ax4.bar(x, noise_rates, width, bottom=effectiveness_rates, label='Noise', color='lightcoral')
    ax4.set_xlabel('Dataset', fontsize=12)
    ax4.set_ylabel('Rate (%)', fontsize=12)
    ax4.set_title('Effective vs Noise References', fontsize=14, fontweight='bold')
    ax4.set_xticks(x)
    ax4.set_xticklabels(datasets, rotation=45, ha='right')
    ax4.legend()
    ax4.grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    output_path = os.path.join(output_dir, '28_sample_level_reference_analysis.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"\nâœ… å›¾è¡¨å·²ä¿å­˜: {output_path}")
    plt.close()

def main():
    """ä¸»å‡½æ•°"""
    # è¯»å–æ˜¾è‘—æå‡å’Œä¸‹é™çš„æ•°æ®é›†
    csv_path = 'analyze/common_features_analysis.csv'
    if not os.path.exists(csv_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return
    
    df = pd.read_csv(csv_path)
    
    # ç­›é€‰æ˜¾è‘—æå‡å’Œä¸‹é™çš„æ•°æ®é›†
    improved = df[df['performance_category'] == 'significantly_improved']
    degraded = df[df['performance_category'] == 'significantly_degraded']
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(improved)} ä¸ªæ˜¾è‘—æå‡çš„æ•°æ®é›†")
    print(f"ğŸ“Š æ‰¾åˆ° {len(degraded)} ä¸ªæ˜¾è‘—ä¸‹é™çš„æ•°æ®é›†")
    
    # é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§çš„æ•°æ®é›†è¿›è¡Œåˆ†æ
    key_datasets = []
    
    # æ˜¾è‘—æå‡çš„æ•°æ®é›†
    for _, row in improved.head(5).iterrows():
        dataset_name = row['dataset']
        dataset_type = row['dataset_type']
        key_datasets.append((dataset_name, dataset_type, 'improved'))
    
    # æ˜¾è‘—ä¸‹é™çš„æ•°æ®é›†
    for _, row in degraded.head(5).iterrows():
        dataset_name = row['dataset']
        dataset_type = row['dataset_type']
        key_datasets.append((dataset_name, dataset_type, 'degraded'))
    
    print(f"\nğŸ” å°†åˆ†æ {len(key_datasets)} ä¸ªæ•°æ®é›†")
    
    # åˆ†ææ¯ä¸ªæ•°æ®é›†
    all_results = []
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    for dataset_name, dataset_type, category in key_datasets:
        try:
            result = analyze_dataset_samples(
                dataset_name=dataset_name,
                dataset_type=dataset_type,
                checkpoint_path=None,  # ä½¿ç”¨é»˜è®¤è·¯å¾„
                num_samples=500,  # æ¯ä¸ªæ•°æ®é›†åˆ†æ500ä¸ªæ ·æœ¬
                device=device
            )
            if result:
                result['category'] = category
                all_results.append(result)
        except Exception as e:
            print(f"âŒ åˆ†ææ•°æ®é›† {dataset_name} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exception(*sys.exc_info())
            continue
    
    # å¯è§†åŒ–ç»“æœ
    if len(all_results) > 0:
        visualize_results(all_results)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        output_csv = 'analyze/sample_level_reference_analysis.csv'
        rows = []
        for result in all_results:
            if result is None:
                continue
            stats = result['stats']
            rows.append({
                'dataset': result['dataset_name'],
                'category': result.get('category', 'unknown'),
                'total_samples': stats['total_samples'],
                'samples_with_references': stats['samples_with_references'],
                'reference_rate': stats.get('reference_rate', 0),
                'total_references': stats['total_references'],
                'effective_references': stats['effective_references'],
                'reference_effectiveness': stats.get('reference_effectiveness', 0),
                'noise_references': stats['noise_references'],
                'reference_noise_ratio': stats.get('reference_noise_ratio', 0),
                'samples_with_effective_refs': stats['samples_with_effective_refs'],
                'effective_rate': stats.get('effective_rate', 0),
                'samples_with_only_noise': stats['samples_with_only_noise'],
                'noise_rate': stats.get('noise_rate', 0),
            })
        
        df_results = pd.DataFrame(rows)
        df_results.to_csv(output_csv, index=False)
        print(f"\nâœ… è¯¦ç»†ç»“æœå·²ä¿å­˜: {output_csv}")
    else:
        print("\nâŒ æ²¡æœ‰è·å¾—ä»»ä½•åˆ†æç»“æœ")

if __name__ == '__main__':
    main()

