# 可学习融合效果差的原因分析

## 🔍 诊断结果

### 1. Checkpoint检查
- ✅ Checkpoint中有 `fusion_weights_logits` 参数
- ✅ 权重形状正确：`[2]`（增量融合方式）
- ✅ 权重值：similarity=0.2250, prompt=0.7750
- ✅ 没有加载警告，权重正确加载

### 2. 权重对比
- **训练后权重**：similarity=0.2250, prompt=0.7750
- **固定权重**：similarity=0.2000, prompt=0.8000
- **差异**：similarity增加了12.5%，prompt减少了3.1%

### 3. 训练配置确认
- ✅ 训练时使用：`use_learnable_fusion: True`
- ✅ 初始权重：similarity=0.2, prompt=0.8
- ✅ 训练任务：MultiGraphPretraining（预训练任务）

## 🎯 问题分析

### 核心问题：训练后的权重可能不是最优的

**可能的原因**：

1. **预训练任务不适合学习融合权重**
   - 预训练使用的是 `MultiGraphPretraining` 任务
   - 这个任务在多个数据集上联合训练，可能不适合学习特定数据集的融合权重
   - 融合权重可能在预训练时学习到了"通用"但"次优"的值

2. **权重学习不充分**
   - 初始权重：similarity=0.2, prompt=0.8
   - 训练后权重：similarity=0.225, prompt=0.775
   - 变化很小（只有12.5%），说明可能没有充分学习

3. **权重学习到了次优值**
   - 训练后权重增加了similarity的权重（从0.2到0.225）
   - 但如果similarity增强在某些数据集上效果不好，这会导致性能下降
   - 从消融实验看，similarity增强在某些数据集上确实效果不如prompt增强

4. **训练目标与推理目标不一致**
   - 预训练时的目标是多个数据集的联合优化
   - 推理时是在特定数据集上评估
   - 融合权重可能在预训练时学习到了"平均最优"，但在特定数据集上不是最优

## 📊 证据支持

### 从消融实验看：
- **Abl1** (similarity only): 在部分数据集上效果不如ARE
- **Abl2** (prompt only): 在部分数据集上效果不如ARE
- **ARE** (完整模型): 在大多数数据集上效果最好

这说明：
- 两个增强器都有贡献，但需要合适的权重组合
- 固定权重（0.2/0.8）可能是经过调优的，比较适合
- 训练后的权重（0.225/0.775）可能不是最优的

## 🔧 解决方案

### 方案1：使用固定权重（推荐，立即修复）

```yaml
# flags.yaml
use_learnable_fusion: False
similarity_enhancer_weight: 0.2
prompt_enhancer_weight: 0.8
```

**理由**：
- 固定权重（0.2/0.8）是基于消融实验调优的
- 在大多数数据集上效果更好
- 简单可靠，不需要重新训练

### 方案2：使用训练后的权重作为固定权重

```yaml
# flags.yaml
use_learnable_fusion: False
similarity_enhancer_weight: 0.225
prompt_enhancer_weight: 0.775
```

**理由**：
- 如果训练后的权重确实学到了有用的信息
- 可以作为固定权重使用

### 方案3：重新训练（长期方案）

如果确实想使用可学习融合：
1. **调整训练策略**：
   - 在特定数据集上微调融合权重
   - 而不是在预训练时学习
   
2. **调整学习率**：
   - 给融合权重单独的学习率
   - 或者使用更小的学习率，避免过度学习

3. **调整初始权重**：
   - 基于消融实验结果设置更好的初始权重
   - 例如：similarity=0.3, prompt=0.7

## 📝 立即行动

### 步骤1：验证固定权重效果

修改 `flags.yaml`：
```yaml
use_learnable_fusion: False
```

然后重新运行推理，对比效果。

### 步骤2：如果固定权重效果好

说明问题确实在于训练后的权重，可以：
- 使用固定权重模式
- 或者尝试方案2（使用训练后的权重值）

### 步骤3：如果固定权重效果也不好

说明问题可能不在权重，需要检查其他方面：
- 模型结构
- 增强器实现
- 数据预处理

## 🎯 结论

**最可能的原因**：训练后的权重（0.225/0.775）不是最优的，固定权重（0.2/0.8）更适合。

**建议**：立即使用固定权重模式验证，如果效果恢复，说明问题确实在于训练后的权重。

