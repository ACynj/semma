#!/usr/bin/env python
"""
ä½¿ç”¨Trial 2çš„epoch 9 checkpointè¿è¡Œè¯„ä¼°ï¼Œå¹¶æ›´æ–°ç»“æœ
"""

import os
import sys
import subprocess
import re
import json
import optuna
import sqlite3
from pathlib import Path
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def parse_metrics_from_output(output):
    """ä»è¾“å‡ºä¸­è§£æMRRå’ŒHits@10"""
    metrics = {}
    
    # æŸ¥æ‰¾MRR
    mrr_patterns = [
        r'mrr(?:-tail)?[:\s]+(\d+\.\d+)',
        r'mrr[:\s]+(\d+\.\d+)',
    ]
    
    for pattern in mrr_patterns:
        matches = re.findall(pattern, output, re.IGNORECASE)
        if matches:
            try:
                metrics['mrr'] = float(matches[-1])
                break
            except:
                pass
    
    # æŸ¥æ‰¾Hits@10
    hits10_patterns = [
        r'hits@10(?:-tail)?[:\s]+(\d+\.\d+)',
        r'hits@10[:\s]+(\d+\.\d+)',
    ]
    
    for pattern in hits10_patterns:
        matches = re.findall(pattern, output, re.IGNORECASE)
        if matches:
            try:
                metrics['hits@10'] = float(matches[-1])
                break
            except:
                pass
    
    return metrics if 'mrr' in metrics and 'hits@10' in metrics else None

def evaluate_with_checkpoint(checkpoint_path, dataset_name, version=None, dataset_type="transductive"):
    """ä½¿ç”¨checkpointåœ¨æ•°æ®é›†ä¸Šè¯„ä¼°"""
    project_root = "/T20030104/ynj/semma"
    
    if dataset_type == "transductive":
        config_path = "config/transductive/inference-fb.yaml"
        cmd = [
            "python", "script/run.py",
            "-c", config_path,
            "--dataset", dataset_name,
            "--ckpt", checkpoint_path,
            "--gpus", "[0]",
            "--epochs", "0",
            "--bpe", "null"
        ]
    else:  # inductive
        config_path = "config/inductive/inference.yaml"
        cmd = [
            "python", "script/run.py",
            "-c", config_path,
            "--dataset", dataset_name,
            "--version", version,
            "--ckpt", checkpoint_path,
            "--gpus", "[0]",
            "--epochs", "0",
            "--bpe", "null"
        ]
    
    try:
        print(f"  è¯„ä¼° {dataset_name}...")
        result = subprocess.run(
            cmd,
            cwd=project_root,
            capture_output=True,
            text=True,
            timeout=1800  # 30åˆ†é’Ÿè¶…æ—¶
        )
        
        if result.returncode == 0:
            metrics = parse_metrics_from_output(result.stdout + result.stderr)
            if metrics:
                print(f"    âœ“ MRR: {metrics['mrr']:.4f}, Hits@10: {metrics['hits@10']:.4f}")
                return metrics
            else:
                print(f"    âš  æ— æ³•è§£ææŒ‡æ ‡")
        else:
            print(f"    âœ— è¯„ä¼°å¤±è´¥")
            print(f"    é”™è¯¯: {result.stderr[-200:]}")
            
    except subprocess.TimeoutExpired:
        print(f"    âœ— è¯„ä¼°è¶…æ—¶")
    except Exception as e:
        print(f"    âœ— è¯„ä¼°å¼‚å¸¸: {e}")
    
    return None

def evaluate_trial2_with_epoch9():
    """ä½¿ç”¨Trial 2çš„epoch 9 checkpointè¿è¡Œè¯„ä¼°"""
    checkpoint_path = "/T20030104/ynj/semma/output/Ultra/JointDataset/2025-11-07-22-27-49/model_epoch_9.pth"
    
    if not os.path.exists(checkpoint_path):
        print(f"âŒ Checkpointä¸å­˜åœ¨: {checkpoint_path}")
        return False
    
    print("="*70)
    print("ğŸ”§ ä½¿ç”¨Trial 2çš„Epoch 9 Checkpointè¿è¡Œè¯„ä¼°")
    print("="*70)
    print(f"Checkpoint: {checkpoint_path}")
    
    # ä»£è¡¨æ€§æ•°æ®é›†åˆ—è¡¨
    representative_datasets = [
        ("FB15k237", None, "transductive"),
        ("WN18RR", None, "transductive"),
        ("CoDExSmall", None, "transductive"),
        ("FB15k237Inductive", "v1", "inductive"),
        ("WN18RRInductive", "v1", "inductive"),
        ("NELLInductive", "v1", "inductive"),
    ]
    
    # è¿è¡Œè¯„ä¼°
    print(f"\nğŸ“Š å¼€å§‹è¯„ä¼°...")
    eval_results = {}
    
    for dataset_name, version, dataset_type in representative_datasets:
        metrics = evaluate_with_checkpoint(checkpoint_path, dataset_name, version, dataset_type)
        if metrics:
            eval_results[dataset_name] = metrics
    
    if not eval_results:
        print("\nâŒ æ²¡æœ‰è·å¾—ä»»ä½•è¯„ä¼°ç»“æœ")
        return False
    
    # è®¡ç®—ç»¼åˆåˆ†æ•°
    total_mrr = sum(m['mrr'] for m in eval_results.values())
    total_hits10 = sum(m['hits@10'] for m in eval_results.values())
    count = len(eval_results)
    
    avg_mrr = total_mrr / count
    avg_hits10 = total_hits10 / count
    score = 0.6 * avg_mrr + 0.4 * avg_hits10
    
    print(f"\nğŸ“ˆ è¯„ä¼°ç»“æœ:")
    print(f"  è¯„ä¼°æ•°æ®é›†æ•°: {len(eval_results)}")
    print(f"  å¹³å‡MRR: {avg_mrr:.4f}")
    print(f"  å¹³å‡Hits@10: {avg_hits10:.4f}")
    print(f"  ç»¼åˆåˆ†æ•°: {score:.4f}")
    
    # æ›´æ–°Optunaæ•°æ®åº“
    study_db = "/T20030104/ynj/semma/optuna_tune/trials/study.db"
    print(f"\nğŸ’¾ æ›´æ–°Optunaæ•°æ®åº“...")
    
    try:
        study = optuna.load_study(
            study_name="enhancement_params_tuning",
            storage=f"sqlite:///{study_db}"
        )
        
        trial_2 = study.trials[2]
        params = trial_2.params
        
        conn = sqlite3.connect(study_db)
        cursor = conn.cursor()
        
        new_value = -score
        
        cursor.execute("SELECT trial_id FROM trials WHERE number = 2")
        trial_id = cursor.fetchone()[0]
        
        # æ›´æ–°trialå€¼
        cursor.execute("""
            UPDATE trial_values 
            SET value = ?, value_type = 'FINITE'
            WHERE trial_id = ? AND objective = 0
        """, (new_value, trial_id))
        
        if cursor.rowcount == 0:
            cursor.execute("""
                INSERT INTO trial_values (trial_id, objective, value, value_type)
                VALUES (?, 0, ?, 'FINITE')
            """, (trial_id, new_value))
        
        # æ›´æ–°trialçŠ¶æ€
        cursor.execute("""
            UPDATE trials 
            SET state = 'COMPLETE' 
            WHERE trial_id = ?
        """, (trial_id,))
        
        conn.commit()
        conn.close()
        
        print(f"  âœ“ æˆåŠŸæ›´æ–°trial 2:")
        print(f"    å€¼: {new_value:.4f} (å¯¹åº”åˆ†æ•°: {score:.4f})")
        print(f"    å‚æ•°: {params}")
        
    except Exception as e:
        print(f"âŒ æ›´æ–°æ•°æ®åº“å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # ä¿å­˜ç»“æœæ–‡ä»¶
    print(f"\nğŸ“ ä¿å­˜trialç»“æœæ–‡ä»¶...")
    trial_dir = "/T20030104/ynj/semma/optuna_tune/trials/trial_2"
    os.makedirs(trial_dir, exist_ok=True)
    
    result = {
        'trial_number': 2,
        'score': score,
        'params': params,
        'eval_results': {
            **eval_results,
            'avg_mrr': avg_mrr,
            'avg_hits10': avg_hits10,
            'score': score
        },
        'timestamp': datetime.now().isoformat(),
        'manually_added': True,
        'note': 'ä½¿ç”¨epoch 9 checkpointè¯„ä¼°ï¼ˆepoch 10æœªå®Œæˆï¼‰'
    }
    
    result_file = os.path.join(trial_dir, 'result.json')
    with open(result_file, 'w') as f:
        json.dump(result, f, indent=2)
    
    print(f"  âœ“ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    print("\n" + "="*70)
    print("âœ… Trial 2è¯„ä¼°å®Œæˆï¼")
    print("="*70)
    
    return True

if __name__ == "__main__":
    success = evaluate_trial2_with_epoch9()
    sys.exit(0 if success else 1)


