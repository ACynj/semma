#!/usr/bin/env python
"""
æ‰‹åŠ¨æ·»åŠ ç¬¬äºŒæ¬¡å®éªŒï¼ˆTrial 1ï¼‰çš„ç»“æœ
ä¸ä¼šä¸­æ–­å½“å‰æ­£åœ¨è¿è¡Œçš„ç¨‹åº
"""

import os
import sys
import re
import json
import optuna
import sqlite3
from pathlib import Path
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def parse_metrics_from_log(log_file):
    """ä»æ—¥å¿—æ–‡ä»¶ä¸­è§£æMRRå’ŒHits@10"""
    if not os.path.exists(log_file):
        return None
    
    with open(log_file, 'r') as f:
        content = f.read()
    
    # æŸ¥æ‰¾testé›†çš„MRRå’ŒHits@10ï¼ˆé€šå¸¸æ˜¯æœ€åä¸€ä¸ªï¼‰
    mrr_pattern = r'mrr(?:-tail)?[:\s]+(\d+\.\d+)'
    hits10_pattern = r'hits@10(?:-tail)?[:\s]+(\d+\.\d+)'
    
    mrr_matches = re.findall(mrr_pattern, content, re.IGNORECASE)
    hits10_matches = re.findall(hits10_pattern, content, re.IGNORECASE)
    
    if mrr_matches and hits10_matches:
        # å–æœ€åä¸€ä¸ªåŒ¹é…ï¼ˆé€šå¸¸æ˜¯testé›†çš„ç»“æœï¼‰
        mrr = float(mrr_matches[-1])
        hits10 = float(hits10_matches[-1])
        return {'mrr': mrr, 'hits@10': hits10}
    
    return None

def find_evaluation_logs_for_trial1():
    """æŸ¥æ‰¾Trial 1çš„è¯„ä¼°æ—¥å¿—æ–‡ä»¶"""
    eval_dir = "/T20030104/ynj/semma/v3_vip_output/Ultra"
    if not os.path.exists(eval_dir):
        return {}
    
    # ä»£è¡¨æ€§æ•°æ®é›†åˆ—è¡¨ï¼ˆä¸è°ƒå‚è„šæœ¬ä¸­ä¸€è‡´ï¼‰
    representative_datasets = [
        ("FB15k237", None, "transductive"),
        ("WN18RR", None, "transductive"),
        ("CoDExSmall", None, "transductive"),
        ("FB15k237Inductive", "v1", "inductive"),
        ("WN18RRInductive", "v1", "inductive"),
        ("NELLInductive", "v1", "inductive"),
    ]
    
    results = {}
    
    for dataset_name, version, dataset_type in representative_datasets:
        dataset_dir = os.path.join(eval_dir, dataset_name)
        if not os.path.exists(dataset_dir):
            print(f"  âš  {dataset_name}: ç›®å½•ä¸å­˜åœ¨")
            continue
        
        # æŸ¥æ‰¾æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶ï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„ï¼Œå› ä¸ºtrial 1çš„è¯„ä¼°åœ¨trial 0ä¹‹åï¼‰
        log_files = sorted(Path(dataset_dir).rglob("log.txt"), key=lambda p: p.stat().st_mtime, reverse=True)
        if not log_files:
            print(f"  âš  {dataset_name}: æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶")
            continue
        
        # å–æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶ï¼ˆtrial 1çš„è¯„ä¼°åº”è¯¥åœ¨trial 0ä¹‹åï¼Œæ‰€ä»¥æœ€æ–°çš„å°±æ˜¯trial 1çš„ï¼‰
        latest_log = log_files[0]  # æœ€æ–°çš„
        
        metrics = parse_metrics_from_log(str(latest_log))
        if metrics:
            results[dataset_name] = metrics
            print(f"  âœ“ {dataset_name}: MRR={metrics['mrr']:.4f}, Hits@10={metrics['hits@10']:.4f}")
        else:
            print(f"  âœ— {dataset_name}: æ— æ³•è§£ææŒ‡æ ‡")
    
    return results

def calculate_score(eval_results):
    """è®¡ç®—ç»¼åˆåˆ†æ•°"""
    if not eval_results:
        return 0.0
    
    total_mrr = 0.0
    total_hits10 = 0.0
    count = 0
    
    for dataset_name, metrics in eval_results.items():
        if isinstance(metrics, dict) and 'mrr' in metrics and 'hits@10' in metrics:
            total_mrr += metrics['mrr']
            total_hits10 += metrics['hits@10']
            count += 1
    
    if count == 0:
        return 0.0
    
    avg_mrr = total_mrr / count
    avg_hits10 = total_hits10 / count
    
    # åŠ æƒå¹³å‡ï¼šMRRæƒé‡0.6ï¼ŒHits@10æƒé‡0.4
    score = 0.6 * avg_mrr + 0.4 * avg_hits10
    
    return score, avg_mrr, avg_hits10

def add_trial_1_manually(result_json_path=None):
    """æ‰‹åŠ¨æ·»åŠ Trial 1çš„ç»“æœ
    
    Args:
        result_json_path: å¯é€‰ï¼ŒåŒ…å«trial 1ç»“æœçš„JSONæ–‡ä»¶è·¯å¾„
                          æ ¼å¼: {"params": {...}, "eval_results": {...}}
    """
    study_db = "/T20030104/ynj/semma/optuna_tune/trials/study.db"
    
    if not os.path.exists(study_db):
        print(f"âŒ Optunaæ•°æ®åº“ä¸å­˜åœ¨: {study_db}")
        return False
    
    print("="*70)
    print("ğŸ”§ æ‰‹åŠ¨æ·»åŠ Trial 1çš„ç»“æœ")
    print("="*70)
    
    # 1. åŠ è½½study
    try:
        study = optuna.load_study(
            study_name="enhancement_params_tuning",
            storage=f"sqlite:///{study_db}"
        )
    except Exception as e:
        print(f"âŒ åŠ è½½studyå¤±è´¥: {e}")
        return False
    
    # 2. æ£€æŸ¥trial 1çš„çŠ¶æ€
    if len(study.trials) < 2:
        print("âš  Trial 1è¿˜ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°çš„trial")
        trial_1_exists = False
    else:
        trial_1 = study.trials[1]
        print(f"\nğŸ“‹ Trial 1å½“å‰çŠ¶æ€:")
        print(f"  çŠ¶æ€: {trial_1.state}")
        print(f"  å€¼: {trial_1.value}")
        print(f"  å‚æ•°: {trial_1.params}")
        trial_1_exists = True
        
        if trial_1.state == optuna.trial.TrialState.COMPLETE and trial_1.value != float('inf'):
            print("\nâš  Trial 1å·²ç»å®Œæˆï¼Œå°†è¦†ç›–ç°æœ‰ç»“æœ")
    
    # 3. è·å–å‚æ•°å’Œè¯„ä¼°ç»“æœ
    params = None
    eval_results = None
    
    # å¦‚æœæä¾›äº†JSONæ–‡ä»¶ï¼Œä»ä¸­è¯»å–
    if result_json_path and os.path.exists(result_json_path):
        print(f"\nğŸ“‚ ä»JSONæ–‡ä»¶è¯»å–ç»“æœ: {result_json_path}")
        try:
            with open(result_json_path, 'r') as f:
                data = json.load(f)
            params = data.get('params')
            eval_results = data.get('eval_results')
            print(f"  âœ“ æˆåŠŸè¯»å–å‚æ•°å’Œè¯„ä¼°ç»“æœ")
        except Exception as e:
            print(f"  âœ— è¯»å–JSONæ–‡ä»¶å¤±è´¥: {e}")
            result_json_path = None
    
    # å¦‚æœå‚æ•°æœªçŸ¥ï¼Œå°è¯•ä»ç°æœ‰trialè·å–
    if params is None:
        if trial_1_exists:
            params = study.trials[1].params
            print(f"\nğŸ“ ä»æ•°æ®åº“è¯»å–çš„å‚æ•°: {params}")
        else:
            print("\nâš  æ— æ³•è·å–å‚æ•°ï¼Œè¯·æä¾›JSONæ–‡ä»¶æˆ–æ‰‹åŠ¨è¾“å…¥")
            print("  è¯·æ‰‹åŠ¨è¾“å…¥å‚æ•°:")
            similarity_threshold = input("  similarity_threshold_init (0.5-0.95, step=0.05): ").strip()
            enhancement_strength = input("  enhancement_strength_init (0.01-0.15, step=0.01): ").strip()
            
            try:
                params = {
                    'similarity_threshold_init': float(similarity_threshold),
                    'enhancement_strength_init': float(enhancement_strength)
                }
            except ValueError:
                print("âŒ å‚æ•°æ ¼å¼é”™è¯¯")
                return False
    
    # 4. ä»è¯„ä¼°æ—¥å¿—ä¸­æå–ç»“æœï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
    if eval_results is None:
        print(f"\nğŸ“Š å°è¯•ä»è¯„ä¼°æ—¥å¿—ä¸­æå–æŒ‡æ ‡...")
        eval_results = find_evaluation_logs_for_trial1()
    
    if not eval_results:
        print("\nâš  æ— æ³•ä»æ—¥å¿—ä¸­è‡ªåŠ¨æå–ç»“æœ")
        print("  è¯·æ‰‹åŠ¨è¾“å…¥è¯„ä¼°ç»“æœ:")
        
        representative_datasets = [
            "FB15k237", "WN18RR", "CoDExSmall",
            "FB15k237Inductive", "WN18RRInductive", "NELLInductive"
        ]
        
        eval_results = {}
        for dataset_name in representative_datasets:
            print(f"\n  {dataset_name}:")
            mrr = input("    MRR: ").strip()
            hits10 = input("    Hits@10: ").strip()
            
            try:
                eval_results[dataset_name] = {
                    'mrr': float(mrr),
                    'hits@10': float(hits10)
                }
            except ValueError:
                print(f"    âš  è·³è¿‡ {dataset_name}ï¼ˆæ ¼å¼é”™è¯¯ï¼‰")
    
    if not eval_results:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„è¯„ä¼°ç»“æœ")
        return False
    
    # 5. è®¡ç®—ç»¼åˆåˆ†æ•°
    score, avg_mrr, avg_hits10 = calculate_score(eval_results)
    print(f"\nğŸ“ˆ è®¡ç®—ç»“æœ:")
    print(f"  è¯„ä¼°æ•°æ®é›†æ•°: {len(eval_results)}")
    print(f"  å¹³å‡MRR: {avg_mrr:.4f}")
    print(f"  å¹³å‡Hits@10: {avg_hits10:.4f}")
    print(f"  ç»¼åˆåˆ†æ•°: {score:.4f}")
    
    # 6. æ›´æ–°Optunaæ•°æ®åº“
    print(f"\nğŸ’¾ æ›´æ–°Optunaæ•°æ®åº“...")
    try:
        conn = sqlite3.connect(study_db)
        cursor = conn.cursor()
        
        # Optunaä½¿ç”¨è´Ÿå€¼å› ä¸ºæˆ‘ä»¬æœ€å°åŒ–ï¼ˆä½†å®é™…æ˜¯æœ€å¤§åŒ–scoreï¼‰
        new_value = -score
        
        if trial_1_exists:
            # æ›´æ–°ç°æœ‰trial
            cursor.execute("SELECT trial_id FROM trials WHERE number = 1")
            trial_id_result = cursor.fetchone()
            if trial_id_result:
                trial_id = trial_id_result[0]
                
                # æ›´æ–°trialå€¼
                cursor.execute("""
                    UPDATE trial_values 
                    SET value = ?, value_type = 'FINITE'
                    WHERE trial_id = ? AND objective = 0
                """, (new_value, trial_id))
                
                # å¦‚æœtrial_valuesè¡¨ä¸­æ²¡æœ‰è®°å½•ï¼Œæ’å…¥ä¸€æ¡
                if cursor.rowcount == 0:
                    cursor.execute("""
                        INSERT INTO trial_values (trial_id, objective, value, value_type)
                        VALUES (?, 0, ?, 'FINITE')
                    """, (trial_id, new_value))
                
                # æ›´æ–°trialçŠ¶æ€ä¸ºCOMPLETE
                cursor.execute("""
                    UPDATE trials 
                    SET state = 'COMPLETE' 
                    WHERE trial_id = ?
                """, (trial_id,))
                
                # æ›´æ–°å‚æ•°ï¼ˆå¦‚æœéœ€è¦ï¼‰
                cursor.execute("""
                    UPDATE trial_params 
                    SET param_value = ?
                    WHERE trial_id = ? AND param_name = 'similarity_threshold_init'
                """, (str(params['similarity_threshold_init']), trial_id))
                
                cursor.execute("""
                    UPDATE trial_params 
                    SET param_value = ?
                    WHERE trial_id = ? AND param_name = 'enhancement_strength_init'
                """, (str(params['enhancement_strength_init']), trial_id))
        else:
            # åˆ›å»ºæ–°çš„trial
            # è·å–study_id
            cursor.execute("SELECT study_id FROM studies WHERE study_name = 'enhancement_params_tuning'")
            study_id_result = cursor.fetchone()
            if not study_id_result:
                print("âŒ æ‰¾ä¸åˆ°study")
                conn.close()
                return False
            study_id = study_id_result[0]
            
            # æ’å…¥æ–°trial
            cursor.execute("""
                INSERT INTO trials (study_id, number, state, datetime_start, datetime_complete)
                VALUES (?, 1, 'COMPLETE', ?, ?)
            """, (study_id, datetime.now().isoformat(), datetime.now().isoformat()))
            
            trial_id = cursor.lastrowid
            
            # æ’å…¥trialå€¼
            cursor.execute("""
                INSERT INTO trial_values (trial_id, objective, value, value_type)
                VALUES (?, 0, ?, 'FINITE')
            """, (trial_id, new_value))
            
            # æ’å…¥å‚æ•°
            cursor.execute("""
                INSERT INTO trial_params (trial_id, param_name, param_value, distribution_json)
                VALUES (?, 'similarity_threshold_init', ?, '{"name": "FloatDistribution", "low": 0.5, "high": 0.95, "step": 0.05}')
            """, (trial_id, str(params['similarity_threshold_init'])))
            
            cursor.execute("""
                INSERT INTO trial_params (trial_id, param_name, param_value, distribution_json)
                VALUES (?, 'enhancement_strength_init', ?, '{"name": "FloatDistribution", "low": 0.01, "high": 0.15, "step": 0.01}')
            """, (trial_id, str(params['enhancement_strength_init'])))
        
        conn.commit()
        conn.close()
        
        print(f"  âœ“ æˆåŠŸæ›´æ–°trial 1:")
        print(f"    å€¼: {new_value:.4f} (å¯¹åº”åˆ†æ•°: {score:.4f})")
        print(f"    çŠ¶æ€: COMPLETE")
        print(f"    å‚æ•°: {params}")
        
    except Exception as e:
        print(f"âŒ æ›´æ–°æ•°æ®åº“å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 7. ä¿å­˜trialç»“æœæ–‡ä»¶
    print(f"\nğŸ“ ä¿å­˜trialç»“æœæ–‡ä»¶...")
    trial_dir = "/T20030104/ynj/semma/optuna_tune/trials/trial_1"
    os.makedirs(trial_dir, exist_ok=True)
    
    result = {
        'trial_number': 1,
        'score': score,
        'params': params,
        'eval_results': {
            **eval_results,
            'avg_mrr': avg_mrr,
            'avg_hits10': avg_hits10,
            'score': score
        },
        'timestamp': datetime.now().isoformat(),
        'manually_added': True  # æ ‡è®°ä¸ºæ‰‹åŠ¨æ·»åŠ 
    }
    
    result_file = os.path.join(trial_dir, 'result.json')
    with open(result_file, 'w') as f:
        json.dump(result, f, indent=2)
    
    print(f"  âœ“ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    # 8. éªŒè¯æ›´æ–°
    print(f"\nğŸ” éªŒè¯æ›´æ–°...")
    study = optuna.load_study(
        study_name="enhancement_params_tuning",
        storage=f"sqlite:///{study_db}"
    )
    
    if len(study.trials) > 1:
        trial_1_updated = study.trials[1]
        print(f"  Trial 1æ–°çŠ¶æ€:")
        print(f"    çŠ¶æ€: {trial_1_updated.state}")
        print(f"    å€¼: {trial_1_updated.value:.4f} (å¯¹åº”åˆ†æ•°: {-trial_1_updated.value:.4f})")
        print(f"    å‚æ•°: {trial_1_updated.params}")
    
    if study.best_trial:
        print(f"\nğŸ† å½“å‰æœ€ä½³trial:")
        print(f"  Trial ID: {study.best_trial.number}")
        print(f"  æœ€ä½³å€¼: {-study.best_trial.value:.4f}")
        print(f"  å‚æ•°: {study.best_trial.params}")
    
    print("\n" + "="*70)
    print("âœ… Trial 1æ·»åŠ å®Œæˆï¼")
    print("="*70)
    print("\nğŸ’¡ æç¤º:")
    print("  - ç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä¸ä¼šå½±å“å½“å‰æ­£åœ¨è¿è¡Œçš„ç¨‹åº")
    print("  - åç»­trialsä¼šåŸºäºè¿™ä¸ªç»“æœç»§ç»­ä¼˜åŒ–")
    print("  - å¯ä»¥ä½¿ç”¨ optuna-dashboard æŸ¥çœ‹æ›´æ–°åçš„ç»“æœ")
    
    return True

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='æ‰‹åŠ¨æ·»åŠ Trial 1çš„ç»“æœ')
    parser.add_argument('--result_json', type=str, default=None,
                       help='åŒ…å«trial 1ç»“æœçš„JSONæ–‡ä»¶è·¯å¾„ï¼ˆæ ¼å¼: {"params": {...}, "eval_results": {...}}ï¼‰')
    args = parser.parse_args()
    
    success = add_trial_1_manually(result_json_path=args.result_json)
    sys.exit(0 if success else 1)

