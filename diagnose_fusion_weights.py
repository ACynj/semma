#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯Šæ–­å¯å­¦ä¹ èåˆæƒé‡é—®é¢˜
æ£€æŸ¥checkpointä¸­çš„æƒé‡æƒ…å†µ
"""

import torch
import torch.nn.functional as F
import os

def diagnose_checkpoint(checkpoint_path):
    """è¯Šæ–­checkpointä¸­çš„èåˆæƒé‡"""
    print("=" * 80)
    print("è¯Šæ–­ Checkpoint ä¸­çš„èåˆæƒé‡")
    print("=" * 80)
    
    if not os.path.exists(checkpoint_path):
        print(f"âŒ Checkpointæ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        return
    
    print(f"\nğŸ“¦ åŠ è½½checkpoint: {checkpoint_path}")
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        # æ£€æŸ¥checkpointç»“æ„
        if isinstance(checkpoint, dict):
            if 'model' in checkpoint:
                model_state = checkpoint['model']
                print("âœ“ CheckpointåŒ…å«'model'é”®")
            else:
                model_state = checkpoint
                print("âœ“ Checkpointç›´æ¥æ˜¯æ¨¡å‹çŠ¶æ€å­—å…¸")
        else:
            model_state = checkpoint
            print("âœ“ Checkpointæ˜¯æ¨¡å‹çŠ¶æ€å­—å…¸")
        
        # æ£€æŸ¥fusion_weights_logits
        print("\n" + "-" * 80)
        print("æ£€æŸ¥ fusion_weights_logits:")
        print("-" * 80)
        
        if 'fusion_weights_logits' in model_state:
            weights = model_state['fusion_weights_logits']
            print(f"âœ“ æ‰¾åˆ° fusion_weights_logits")
            print(f"  - Shape: {weights.shape}")
            print(f"  - Dtype: {weights.dtype}")
            print(f"  - Values (logits): {weights}")
            
            # è®¡ç®—softmaxåçš„æƒé‡
            normalized = F.softmax(weights, dim=0)
            print(f"\n  - å½’ä¸€åŒ–åçš„æƒé‡ (softmax):")
            
            if len(weights) == 2:
                print(f"    * similarity_enhancer: {normalized[0]:.4f}")
                print(f"    * prompt_enhancer: {normalized[1]:.4f}")
                print(f"    * èåˆå…¬å¼: final = r + {normalized[0]:.4f}*r1_delta + {normalized[1]:.4f}*r2_delta")
            elif len(weights) == 3:
                print(f"    * åŸå§‹r: {normalized[0]:.4f}")
                print(f"    * similarity_enhancer: {normalized[1]:.4f}")
                print(f"    * prompt_enhancer: {normalized[2]:.4f}")
                print(f"    âš ï¸ è¿™æ˜¯æ—§ç‰ˆæœ¬çš„3æƒé‡æ ¼å¼ï¼")
                print(f"    * èåˆå…¬å¼: final = {normalized[0]:.4f}*r + {normalized[1]:.4f}*r1 + {normalized[2]:.4f}*r2")
            else:
                print(f"    âš ï¸ æœªçŸ¥çš„æƒé‡æ•°é‡: {len(weights)}")
        else:
            print("âŒ Checkpointä¸­æ²¡æœ‰ fusion_weights_logits å‚æ•°ï¼")
            print("   è¿™æ„å‘³ç€checkpointæ˜¯åœ¨å›ºå®šæƒé‡æ¨¡å¼ä¸‹è®­ç»ƒçš„")
        
        # æ£€æŸ¥å…¶ä»–ç›¸å…³å‚æ•°
        print("\n" + "-" * 80)
        print("æ£€æŸ¥å…¶ä»–å¢å¼ºå™¨ç›¸å…³å‚æ•°:")
        print("-" * 80)
        
        enhancer_keys = [k for k in model_state.keys() if 'enhancer' in k.lower() or 'fusion' in k.lower()]
        if enhancer_keys:
            print(f"âœ“ æ‰¾åˆ° {len(enhancer_keys)} ä¸ªç›¸å…³å‚æ•°:")
            for key in enhancer_keys[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                param = model_state[key]
                if isinstance(param, torch.Tensor):
                    print(f"  - {key}: shape={param.shape}, dtype={param.dtype}")
                else:
                    print(f"  - {key}: {type(param)}")
        else:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¢å¼ºå™¨ç›¸å…³å‚æ•°")
        
        # æ£€æŸ¥æ¨¡å‹ç»“æ„
        print("\n" + "-" * 80)
        print("æ£€æŸ¥æ¨¡å‹ç»“æ„ä¿¡æ¯:")
        print("-" * 80)
        
        # å°è¯•æ¨æ–­æ¨¡å‹ç±»å‹
        has_similarity_enhancer = any('similarity' in k for k in model_state.keys())
        has_prompt_enhancer = any('prompt' in k for k in model_state.keys())
        
        print(f"  - åŒ…å«similarity_enhancer: {has_similarity_enhancer}")
        print(f"  - åŒ…å«prompt_enhancer: {has_prompt_enhancer}")
        
        # ç»Ÿè®¡å‚æ•°æ•°é‡
        total_params = len(model_state)
        print(f"  - æ€»å‚æ•°æ•°é‡: {total_params}")
        
    except Exception as e:
        print(f"âŒ åŠ è½½checkpointå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

def check_inference_logs(log_file):
    """æ£€æŸ¥æ¨ç†æ—¥å¿—ä¸­çš„è­¦å‘Š"""
    print("\n" + "=" * 80)
    print("æ£€æŸ¥æ¨ç†æ—¥å¿—ä¸­çš„è­¦å‘Š")
    print("=" * 80)
    
    if not os.path.exists(log_file):
        print(f"âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
        return
    
    with open(log_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # æŸ¥æ‰¾è­¦å‘Šä¿¡æ¯
    warnings = []
    for i, line in enumerate(lines):
        if 'warning' in line.lower() or 'Warning' in line or 'ç¼ºå¤±' in line or 'Missing' in line:
            warnings.append((i+1, line.strip()))
    
    if warnings:
        print(f"âš ï¸ æ‰¾åˆ° {len(warnings)} ä¸ªè­¦å‘Š:")
        for line_num, warning in warnings[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"  Line {line_num}: {warning}")
    else:
        print("âœ“ æ²¡æœ‰æ‰¾åˆ°è­¦å‘Šä¿¡æ¯")

if __name__ == '__main__':
    # æ£€æŸ¥checkpoint
    checkpoint_path = '/T20030104/ynj/semma/ckpts/fusion.pth'
    diagnose_checkpoint(checkpoint_path)
    
    # æ£€æŸ¥æ¨ç†æ—¥å¿—
    log_file = '/T20030104/ynj/semma/fusion_output/Ultra/FBNELL/2025-11-15-10-04-19/log.txt'
    check_inference_logs(log_file)
    
    print("\n" + "=" * 80)
    print("è¯Šæ–­å®Œæˆ")
    print("=" * 80)

